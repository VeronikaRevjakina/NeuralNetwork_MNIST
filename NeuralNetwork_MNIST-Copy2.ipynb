{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Activation functions](https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid\n",
    "def sigmoid_f(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "def sigmoid_df(x):  \n",
    "    sig=sigmoid_f(x)\n",
    "    return sig*(1-sig)\n",
    "    \n",
    "#ReLU\n",
    "def ReLU_f_over(x):\n",
    "    return x*(x>0)\n",
    "\n",
    "def ReLU_f(x): \n",
    "    return np.where(x > 0, x, 0)\n",
    "\n",
    "\n",
    "def ReLU_df(x):\n",
    "    return np.where(x <= 0, 0, 1)\n",
    "\n",
    "#Softmax\n",
    "def softmax_my(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def softmax_df(x):  \n",
    "    soft=softmax_f(x)\n",
    "    return soft*(1-soft)\n",
    "\n",
    "def softmax_f(x):  # работает\n",
    "    temp = math.e**x\n",
    "    div = temp.sum(axis=1)\n",
    "    return np.transpose((np.divide(np.transpose(temp), np.transpose(div))))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# Fetch MNIST dataset and create a local copy.\n",
    "if os.path.exists('mnist.npz'):\n",
    "    with np.load('mnist.npz', 'r') as data:\n",
    "        X = data['X']\n",
    "        y = data['y']\n",
    "else:\n",
    "    mnist = fetch_mldata(\"mnist-original\")\n",
    "    X, y = mnist.data / 255.0, mnist.target\n",
    "    np.savez('mnist.npz', X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Convert labels to One Hot Encoded\n",
    "num_digits = 10\n",
    "encoder = OneHotEncoder(categorical_features =[0]) \n",
    "y_one_hot = encoder.fit_transform(y.reshape(-1, 1)).toarray()\n",
    "print(y_one_hot[50000,:])\n",
    "\n",
    "# def to_one_hot(y): \n",
    "#     one_hot_y = np.zeros((len(y), num_digits))\n",
    "#     for i in range(len(y)):\n",
    "#         one_hot_y[i, int(one_hot_y[i])] = 1\n",
    "#     return one_hot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X,y=shuffle(X,y)\n",
    "#Split into test , train based on Kaggle\n",
    "X_train=X[:60000,:]\n",
    "y_train=y_one_hot[:60000,:]\n",
    "\n",
    "X_test=X[60000:,:]\n",
    "y_test=y_one_hot[60000:,:]\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_initialization(size_prev, size_next):  # HE initialization for matrix weights\n",
    "    return np.random.randn(size_prev, size_next) * np.sqrt(2.0/size_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expects weights and bias to be a matrix and a vector, activation_function to be a value= 1,2 or 3\n",
    "#Use when need to store z, h at each layer (for deltas)\n",
    "def layer_predict(inputs, weights, bias, activation_function):\n",
    "    #main sum counting z\n",
    "    #bias as vector adds to each row of weight matrix\n",
    "    #example: weights (300, 784), inputs (10000,784), bias (300,) then out (10000, 300)\n",
    "    out = np.add(np.dot(weights, inputs.T).T, bias)\n",
    "    # return z and h=f(z), f activation as parameter\n",
    "    if activation_function == 1:\n",
    "        return out, sigmoid_f(out)\n",
    "    if activation_function == 2:\n",
    "        return out, ReLU_f(out)\n",
    "    if activation_function == 3:\n",
    "        return out, softmax_f(out)\n",
    "#Expects z to be a matrix , activation_function to be a value= 1,2 or 3\n",
    "#Use when counting delta back propagate using derivatives\n",
    "def layer_back_propagate_derivatives(z, activation_function):\n",
    "    if activation_function == 1:\n",
    "        return sigmoid_df(z)\n",
    "    if activation_function == 2:\n",
    "        return ReLU_df(z)\n",
    "    if activation_function == 3:\n",
    "        return softmax_df(z)\n",
    "    \n",
    "#Expects weights and bias to be a list of matrixes and a list of vectors \n",
    "#Use when given input data gets output without storing hidden layers values\n",
    "def neural_predict(x_data, weights_in, biases_in, neural_architecture):  \n",
    "    #for each layer in neural architecture (same dim as weights)\n",
    "    activation_functions=neural_architecture[:,2]\n",
    "    h=[]\n",
    "    \n",
    "    for layer in range(0, len(neural_architecture)):  \n",
    "    \n",
    "        #initial layer then take x_data as input\n",
    "        if layer == 0:\n",
    "            z_temp, h_temp = layer_predict(x_data, weights_in[layer],biases_in[layer], activation_functions[layer])\n",
    "            h = h_temp\n",
    "        else:\n",
    "            #take h-previous layer output as input\n",
    "            z_temp, h_temp = layer_predict(h, weights_in[layer],biases_in[layer], activation_functions[layer])\n",
    "            h = h_temp\n",
    "\n",
    "    return h\n",
    "    \n",
    "def convert_to_binary(vector):\n",
    "    row_maxes = vector.max(axis=1).reshape(-1, 1)\n",
    "    vector[:] = np.where(vector == row_maxes, 1, 0)\n",
    "    return vector\n",
    "\n",
    "def root_mean_square_error(y_predict,y_actual):\n",
    "    y_predict=convert_to_binary(y_predict)\n",
    "    mse=np.sum(np.power(y_actual-y_predict,2))/len(y_predict)\n",
    "    return np.sqrt(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_by_argmax(y_data, prediction):  # argmax for MSE gradient\n",
    "    argmaxes = np.argmax(prediction, axis=1)\n",
    "    temp = np.choose(argmaxes, y_data.T) - np.ones(len(prediction))\n",
    "    temp = temp * temp\n",
    "    return np.sum(temp) / len(y_data)\n",
    "\n",
    "\n",
    "def calculate_prediction(x_data, y_data, w_matrices, biases, activation_functions):  # prediction for accuracy\n",
    "    h = []\n",
    "    for i in range(0, len(w_matrices)):  # forward one batch\n",
    "\n",
    "        if i == 0:\n",
    "            z_temp, h_temp =layer_predict(x_data, w_matrices[i],\n",
    "                                           biases[i], activation_functions[i])\n",
    "            h = h_temp\n",
    "        else:\n",
    "            z_temp, h_temp = layer_predict(h, w_matrices[i],\n",
    "                                           biases[i], activation_functions[i])\n",
    "            h = h_temp\n",
    "\n",
    "    return calculate_by_argmax(y_data, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch_mini_batch_gradient_step(X_train,y_train,w_weights,b_biases,neural_architecture,activation_functions,learning_rate,num_epoches,batch_size):\n",
    "    #A list of outputs of each layer\n",
    "    h =[]\n",
    "    #A list of weightned sum for each layer\n",
    "    z=[]\n",
    "    weights = w_weights.copy()\n",
    "    biases = b_biases.copy()\n",
    "    X_train,y_train=shuffle(X_train,y_train)\n",
    "    n_minibatches = X_train.shape[0] // batch_size #1875\n",
    "    i = 0\n",
    "    for i in range(n_minibatches):\n",
    "        #A list of outputs of each layer\n",
    "        h =[]\n",
    "        #A list of weightned sum for each layer\n",
    "        z=[]\n",
    "        deltas=[]\n",
    "        X_mini=X_train[i * batch_size:(i + 1)*batch_size, :] #(32,784)\n",
    "        y_mini=y_train[i * batch_size:(i + 1)*batch_size,:] #(32,10)\n",
    "        #print(np.shape(X_mini))   \n",
    "        #print(np.shape(y_mini)) \n",
    "        N=X_mini.shape[0] #32...\n",
    "        #PARAMETERS\n",
    "            \n",
    "        #Forward propagation\n",
    "        layers_amount=len(neural_architecture)\n",
    "        #weights=w_weights.copy()\n",
    "        #biases=b_biases.copy()\n",
    "        for layer in range(0, layers_amount):\n",
    "            #For initial layer take X as input\n",
    "            if layer==0:\n",
    "                inputs=X_mini\n",
    "                #z_temp, h_temp= layer_predict(X_mini, weights[layer], biases[layer], activation_functions[layer])\n",
    "            #For any other layer take previous layer output as input\n",
    "            else:\n",
    "                inputs=h[layer-1]\n",
    "                #z_temp, h_temp= layer_predict(h[layer-1], weights[layer], biases[layer], activation_functions[layer])\n",
    "            #Store as lists\n",
    "            z_temp, h_temp= layer_predict(inputs, weights[layer], biases[layer], activation_functions[layer])\n",
    "            z.append(z_temp) #0=(32,300) 1=(32,100) 2=(32,10)\n",
    "            h.append(h_temp)\n",
    "#             print(\"Layer Outputs\")\n",
    "#             print(h[layer])\n",
    "#             print(layer)\n",
    "#             print(z[layer])\n",
    "                \n",
    "        #y_predict=neural_predict(X_mini,weights,biases,neural_architecture) same as h[layers_amount - 1]\n",
    "        # z,y_predict=layer_predict(h[layer_amount-1],weights[layer_amount-1],biases[layer_amount-1],\n",
    "        #activation_functions[layer_amount-1])\n",
    "        #error=y_mini-y_predict \n",
    "            \n",
    "        #DELTA INITIAL AND HIDDEN HERE\n",
    "            \n",
    "        #Initialize empty list size as amount of layers in network\n",
    "        deltas= np.empty(layers_amount, dtype=object)\n",
    "        #Count last delta based on (1)\n",
    "        #(32,10)\n",
    "        delta_last = np.multiply((h[layers_amount - 1] - y_mini),layer_back_propagate_derivatives(z[layers_amount - 1], activation_functions[layers_amount - 1])) \n",
    "        #Store last delta in list\n",
    "#         print(\"Delta Last\")\n",
    "#         print(delta_last)\n",
    "        deltas[layers_amount-1]=delta_last # matrix size (dataset_size,amount_of_neurons_on_this_layer) transpose weights\n",
    "        #Back propagating with step=1 , stop=-1 (need count on layer=0) \n",
    "        for layer in range(layers_amount-2,-1,-1):\n",
    "            #Counting delta on hidden layers based on (2)\n",
    "            deltas[layer]=np.multiply((deltas[layer+1]).dot(weights[layer+1]),layer_back_propagate_derivatives(z[layer], activation_functions[layer]))    \n",
    "#         for layer in range(0, layers_amount):\n",
    "#             print(\"Deltas\")\n",
    "#             print(i)\n",
    "#             print(deltas[layer])\n",
    "        #PARAMETERS UPDATES USING DELTAS\n",
    "        for layer in range(0, layers_amount):\n",
    "            #For initial layer take X as input\n",
    "            if layer==0:\n",
    "                inputs=X_mini\n",
    "            #For any other layer take previous layer output as input\n",
    "            else:\n",
    "                inputs=h[layer-1]\n",
    "            #update weights\n",
    "            lN=learning_rate/N\n",
    "            biases[layer]=biases[layer]-lN*np.sum(deltas[layer],axis=0)\n",
    "            weights[layer]=weights[layer]-lN*((deltas[layer].T).dot(inputs))\n",
    "#             print(\"Learned\")\n",
    "#             print(layer)\n",
    "#             print(biases[layer])\n",
    "#             print(layer)\n",
    "#             print(\"Weights\")\n",
    "#             print(weights[layer] )\n",
    "    return weights,biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gradient_descent(X_train,y_train,neural_architecture,learning_rate,num_epoches,batch_size):\n",
    "    #A list of matrixes size of (new_layer_neurons_amount,prev_layer_neurons_amount)\n",
    "    w_weights=[]\n",
    "    #A list of vectors size of (new_layer_neurons_amount,1)\n",
    "    b_biases=[]\n",
    "    accuracy=[]\n",
    "    accuracy2=[]\n",
    "   \n",
    "    for layer in range(0, len(neural_architecture)):\n",
    "        #For first time forward propagation random initialization\n",
    "        #w_weights.append(np.full((neural_architecture[layer][1], neural_architecture[layer][0]), 0.99))\n",
    "        w_weights.append(he_initialization(neural_architecture[layer,1],neural_architecture[layer,0]))#(300, 784) (100, 300) (10, 100)\n",
    "        b_biases.append(np.zeros(neural_architecture[layer][1])) #(300,) (100,) (10,)\n",
    "#         print(\"Initial weights random\")\n",
    "#         print(w_weights[layer])\n",
    "#         print(b_biases[layer])\n",
    "    #Just to store as list    \n",
    "    activation_functions=neural_architecture[:,2]\n",
    "    it=0\n",
    "    for it in range(num_epoches):\n",
    "        #print(weights[0][::100,::50])\n",
    "        #print(biases[0][::100])\n",
    "        w1=w_weights\n",
    "        b1=b_biases\n",
    "        w_weights,b_biases=one_epoch_mini_batch_gradient_step(X_train,y_train,w_weights,b_biases,neural_architecture,activation_functions,learning_rate,num_epoches,batch_size)\n",
    "#         for layer in range(0, len(neural_architecture)):\n",
    "#             print(\"Epoches changed from initial?\")\n",
    "#             print(w_weights[layer])\n",
    "#             print(b_biases[layer])\n",
    "        y_predict=neural_predict(X_test,w_weights,b_biases,neural_architecture)\n",
    "#         print(y_predict)\n",
    "#         convert_to_binary(y_predict)\n",
    "         \n",
    "        print(it)\n",
    "        #accuracy.append(calculate_prediction(X_test, y_test, w_weights, b_biases, activation_functions))\n",
    "        accuracy2.append(calculate_by_argmax(y_test,y_predict))\n",
    "        convert_to_binary(y_predict)\n",
    "        accuracy.append(accuracy_score(y_test,y_predict)*100)\n",
    "        print(accuracy)\n",
    "        print(accuracy2)\n",
    "    return w_weights,b_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[9.99]\n",
      "[0.9001]\n",
      "1\n",
      "[9.99, 9.92]\n",
      "[0.9001, 0.9008]\n",
      "2\n",
      "[9.99, 9.92, 10.15]\n",
      "[0.9001, 0.9008, 0.8985]\n",
      "3\n",
      "[9.99, 9.92, 10.15, 9.9]\n",
      "[0.9001, 0.9008, 0.8985, 0.901]\n",
      "4\n",
      "[9.99, 9.92, 10.15, 9.9, 10.2]\n",
      "[0.9001, 0.9008, 0.8985, 0.901, 0.898]\n",
      "5\n",
      "[9.99, 9.92, 10.15, 9.9, 10.2, 10.31]\n",
      "[0.9001, 0.9008, 0.8985, 0.901, 0.898, 0.8969]\n",
      "6\n",
      "[9.99, 9.92, 10.15, 9.9, 10.2, 10.31, 10.33]\n",
      "[0.9001, 0.9008, 0.8985, 0.901, 0.898, 0.8969, 0.8967]\n",
      "7\n",
      "[9.99, 9.92, 10.15, 9.9, 10.2, 10.31, 10.33, 10.42]\n",
      "[0.9001, 0.9008, 0.8985, 0.901, 0.898, 0.8969, 0.8967, 0.8958]\n",
      "8\n",
      "[9.99, 9.92, 10.15, 9.9, 10.2, 10.31, 10.33, 10.42, 10.32]\n",
      "[0.9001, 0.9008, 0.8985, 0.901, 0.898, 0.8969, 0.8967, 0.8958, 0.8968]\n",
      "9\n",
      "[9.99, 9.92, 10.15, 9.9, 10.2, 10.31, 10.33, 10.42, 10.32, 10.11]\n",
      "[0.9001, 0.9008, 0.8985, 0.901, 0.898, 0.8969, 0.8967, 0.8958, 0.8968, 0.8989]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-04ea3437f78d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mneural_architecture\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mweights_item\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbias_item\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmini_batch_gradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mneural_architecture\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epoches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-160-3bf6f5a3d022>\u001b[0m in \u001b[0;36mmini_batch_gradient_descent\u001b[1;34m(X_train, y_train, neural_architecture, learning_rate, num_epoches, batch_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mw1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mb1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_biases\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mw_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_biases\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mone_epoch_mini_batch_gradient_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_biases\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mneural_architecture\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation_functions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epoches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m#         for layer in range(0, len(neural_architecture)):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#             print(\"Epoches changed from initial?\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-153-fadfb649fe31>\u001b[0m in \u001b[0;36mone_epoch_mini_batch_gradient_step\u001b[1;34m(X_train, y_train, w_weights, b_biases, neural_architecture, activation_functions, learning_rate, num_epoches, batch_size)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mlN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mbiases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlN\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlN\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;31m#             print(\"Learned\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;31m#             print(layer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rmse=[]\n",
    "omega=[]\n",
    "omega0=[]\n",
    "rmse_train=[]\n",
    "\n",
    "#Already initialized\n",
    "#X_test (10000, 784)\n",
    "#y_test (10000, 10)\n",
    "\n",
    "#X_train (60000, 784)\n",
    "#y_train (60000, 10)\n",
    "      \n",
    "start = time.time()\n",
    "    \n",
    "neural_architecture= np.array([[784, 300, 1, 0],[300, 10, 3, 0]])\n",
    "\n",
    "weights_item,bias_item=mini_batch_gradient_descent(X_train,y_train,neural_architecture,learning_rate = 0.01,num_epoches=30,batch_size=32)\n",
    "stop = time.time()\n",
    "duration = stop-start\n",
    "print(duration)\n",
    "    \n",
    "        \n",
    "#NEED TO PLOT ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def mse_plot(rmse):  \n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(rmse, label=\"MSE train\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "mse_plot(rmse)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas= np.empty(5, dtype=object)\n",
    "print(deltas)\n",
    "omega=np.full((3, 2), 0.5)\n",
    "deltas[2]=omega\n",
    "print(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test=shuffle(X_test,y_test)\n",
    "inputs=X_test[:100,:]  \n",
    "weights=[]\n",
    "neural_architecture= np.array([[784, 300, 1, 0],[300, 100, 1, 0],[100, 10, 3, 0]])\n",
    "activation_functions=neural_architecture[:,2]\n",
    "biases=[]\n",
    "#A list of outputs of each layer\n",
    "h =[]\n",
    "#A list of weightned sum for each layer\n",
    "z=[]\n",
    "deltas= np.zeros(len(neural_architecture), dtype=object)    \n",
    "for layer in range(0, len(neural_architecture)):\n",
    "    #For first time forward propagation random initialization\n",
    "    #weights.append(he_initialization(neural_architecture[layer,1],neural_architecture[layer,0]))\n",
    "    #weights.append(np.zeros(neural_architecture[layer][1],neural_architecture[layer][0]))\n",
    "    weights.append(np.full((neural_architecture[layer][1], neural_architecture[layer][0]), 0))\n",
    "    biases.append(np.zeros(neural_architecture[layer][1]))\n",
    "    #Just to store as list\n",
    "\n",
    "    \n",
    "out = np.add(np.dot(weights[0], inputs.T).T, biases[0])\n",
    "#print(np.shape(weights))\n",
    "#print( len(neural_architecture))\n",
    "#print(len(weights))\n",
    "\n",
    "z,y_predict=layer_predict(inputs,weights[0],biases[0],1)\n",
    "z,y2=layer_predict(y_predict,weights[1],biases[1],1)\n",
    "z,y3=layer_predict(y2,weights[2],biases[2],3)\n",
    "\n",
    "y3_2=neural_predict(inputs,weights, biases, neural_architecture)\n",
    "#print(np.shape(y3_2))\n",
    "#convert_to_binary(y_predict)\n",
    "#print(softmax_f(out3))\n",
    "layers_amount=len(neural_architecture)\n",
    "        #weights=w_weights.copy()\n",
    "        #biases=b_biases.copy()\n",
    "        #A list of outputs of each layer\n",
    "h =[]\n",
    "#A list of weightned sum for each layer\n",
    "z=[]\n",
    "for layer in range(0, layers_amount):\n",
    "            #For initial layer take X as input\n",
    "    if layer==0:\n",
    "        inputs1=X_test[:100,:]\n",
    "                #z_temp, h_temp= layer_predict(X_mini, weights[layer], biases[layer], activation_functions[layer])\n",
    "            #For any other layer take previous layer output as input\n",
    "    else:\n",
    "        inputs1=h[layer-1]\n",
    "                #z_temp, h_temp= layer_predict(h[layer-1], weights[layer], biases[layer], activation_functions[layer])\n",
    "            #Store as lists\n",
    "    z_temp, h_temp= layer_predict(inputs1, weights[layer], biases[layer], activation_functions[layer])\n",
    "    z.append(z_temp) #0=(32,300) 1=(32,100) 2=(32,10)\n",
    "    h.append(h_temp)\n",
    "#print(np.shape(h[layers_amount - 1] - y_test[:100,:]))\n",
    "#print(np.shape(layer_back_propagate_derivatives(z[layers_amount - 1], activation_functions[layers_amount - 1])))\n",
    "delta_last = np.multiply((h[layers_amount - 1] - y_test[:100,:]),layer_back_propagate_derivatives(z[layers_amount - 1], activation_functions[layers_amount - 1]))\n",
    "#print( h[layers_amount - 1] - y_test[:100,:])\n",
    "#print(delta_last)\n",
    "deltas[layers_amount-1]=delta_last\n",
    "\n",
    "for layer in range(layers_amount-2,-1,-1):\n",
    "    #Counting delta on hidden layers based on (2)\n",
    "    #print(np.shape(layer_back_propagate_derivatives(z[layer], activation_functions[layer])))\n",
    "    deltas[layer]=np.multiply((deltas[layer+1]).dot(weights[layer+1]),layer_back_propagate_derivatives(z[layer], activation_functions[layer])) \n",
    "\n",
    "print(np.shape(deltas[2]))\n",
    "\n",
    "for layer in range(0, layers_amount):\n",
    "    #For initial layer take X as input\n",
    "    if layer==0:\n",
    "        inputs2=X_test[:100,:]\n",
    "    #For any other layer take previous layer output as input\n",
    "    else:\n",
    "        inputs2=h[layer-1]\n",
    "                #update weights\n",
    "    N=100\n",
    "    #print(np.shape(weights[layer]))\n",
    "    biases[layer]=biases[layer]-0.001*np.sum(deltas[layer],axis=0)/N\n",
    "    weights[layer]=weights[layer]-0.001*((deltas[layer].T).dot(inputs2))/N\n",
    "    #print(weights[layer])\n",
    "print(deltas[2].T)\n",
    "print(h[1])\n",
    "print((deltas[2].T).dot(h[1]))\n",
    "print(weights[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer=0\n",
    "for layer in range(len(neural_architecture)):\n",
    "    #print(np.shape(weights[layer]))\n",
    "    print(len(neural_architecture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([[0.5, 0.5, 0.5, 0.5,0.5,0.5, 0.5, 0.5, 0.5,0.5],\n",
    "             [0.5, 0.5, 0.5, 0.5,0.5,0.5, 0.5, 0.5, 0.5,0.5],\n",
    "             [0.5, 0.5, 0.5, 0.5,0.5,0.5, 0.5, 0.5, 0.5,0.5]])\n",
    "print(softmax_f(xs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[::2000,::50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(-5.62601022e-051 )\n",
    "numbers = [1.74408899e-012, 2.37943956e-004, 2.63039636e-006, 2.55056039e-010,\n",
    "  3.21408160e-051, 9.99759377e-001, 2.54537571e-008, 2.25822913e-008,\n",
    "  2.00556809e-037, 2.19572601e-128]\n",
    "\n",
    "for number in numbers:\n",
    "    print(f'{number:9.51f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63545512 0.1079984  0.71183677 0.43545901 0.22038128 0.20563826\n",
      "  0.95610961 0.81038951]\n",
      " [0.29182697 0.81015226 0.77189123 0.88343589 0.59548193 0.37270566\n",
      "  0.99845906 0.67199526]\n",
      " [0.76884845 0.20407328 0.89136258 0.06528111 0.94945119 0.29110495\n",
      "  0.23255144 0.846693  ]\n",
      " [0.60169768 0.85712308 0.8410921  0.18386703 0.51960696 0.17866907\n",
      "  0.52596265 0.66310269]\n",
      " [0.75487943 0.97319764 0.98954629 0.63427001 0.35049353 0.13045448\n",
      "  0.9823206  0.11418535]\n",
      " [0.07500125 0.5360988  0.18971054 0.31182801 0.97647321 0.09865844\n",
      "  0.25085084 0.8066556 ]\n",
      " [0.18699095 0.36253489 0.47442783 0.35574654 0.96519    0.8248316\n",
      "  0.05706355 0.79536978]\n",
      " [0.02832364 0.99930732 0.48939381 0.32887041 0.05291127 0.61949636\n",
      "  0.21031375 0.46299726]\n",
      " [0.74089384 0.93413143 0.41533738 0.70721778 0.15872329 0.98062316\n",
      "  0.09897326 0.90376138]\n",
      " [0.17718098 0.78990528 0.98451477 0.45298997 0.94253666 0.57075748\n",
      "  0.87283106 0.63864766]\n",
      " [0.31668118 0.8975891  0.02104956 0.21191122 0.23980325 0.50840185\n",
      "  0.80445709 0.99694903]\n",
      " [0.29044845 0.93639286 0.96378745 0.40017765 0.49266527 0.22684421\n",
      "  0.84498773 0.61796252]\n",
      " [0.53256359 0.83125225 0.20657229 0.14162159 0.88259614 0.24763042\n",
      "  0.42498904 0.72227773]\n",
      " [0.65637262 0.1282143  0.01669136 0.3716197  0.07399711 0.64757284\n",
      "  0.47181629 0.13344532]\n",
      " [0.87533838 0.61868561 0.70672167 0.24364001 0.31927218 0.68952078\n",
      "  0.00757548 0.57675974]\n",
      " [0.88070778 0.83171937 0.74815173 0.40498305 0.77387053 0.36510855\n",
      "  0.36586761 0.56472055]\n",
      " [0.51387401 0.87232375 0.16590201 0.12110268 0.31861324 0.89023738\n",
      "  0.91217032 0.99541964]\n",
      " [0.60825289 0.74289124 0.50866533 0.34136916 0.23152943 0.97090191\n",
      "  0.99336209 0.45030184]\n",
      " [0.52643554 0.0867472  0.31831676 0.2245742  0.73263788 0.15021698\n",
      "  0.44788421 0.78362886]\n",
      " [0.65819082 0.56202317 0.99973197 0.96597069 0.88264923 0.37540971\n",
      "  0.28040132 0.12666634]]\n",
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epoches = 1\n",
    "batch_size = 20\n",
    "\n",
    "def data_generation(size_1, size_2):\n",
    "    return np.random.rand(size_1, size_2)\n",
    "\n",
    "gen_data = data_generation(20, 8)\n",
    "#y_data = data_generation(20, 2)\n",
    "y_data=np.full((20,2), 1)\n",
    "#y_data=np.random.randint(0,2,(20,2))\n",
    "#gen_data=np.full((20,8), 0.5)\n",
    "list_architecture = np.array([\n",
    "        [8, 6, 1],\n",
    "        [6, 4, 2],\n",
    "        [4, 2, 3]\n",
    "    ])\n",
    "print(gen_data)\n",
    "print(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights random\n",
      "[[0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      " [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      " [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      " [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      " [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      " [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Initial weights random\n",
      "[[0.99 0.99 0.99 0.99 0.99 0.99]\n",
      " [0.99 0.99 0.99 0.99 0.99 0.99]\n",
      " [0.99 0.99 0.99 0.99 0.99 0.99]\n",
      " [0.99 0.99 0.99 0.99 0.99 0.99]]\n",
      "[0. 0. 0. 0.]\n",
      "Initial weights random\n",
      "[[0.99 0.99 0.99 0.99]\n",
      " [0.99 0.99 0.99 0.99]]\n",
      "[0. 0.]\n",
      "Layer Outputs\n",
      "[[0.99539075 0.99539075 0.99539075 0.99539075 0.99539075 0.99539075]\n",
      " [0.99523646 0.99523646 0.99523646 0.99523646 0.99523646 0.99523646]\n",
      " [0.99253669 0.99253669 0.99253669 0.99253669 0.99253669 0.99253669]\n",
      " [0.99250338 0.99250338 0.99250338 0.99250338 0.99250338 0.99250338]\n",
      " [0.99185791 0.99185791 0.99185791 0.99185791 0.99185791 0.99185791]\n",
      " [0.99182772 0.99182772 0.99182772 0.99182772 0.99182772 0.99182772]\n",
      " [0.98196318 0.98196318 0.98196318 0.98196318 0.98196318 0.98196318]\n",
      " [0.98274818 0.98274818 0.98274818 0.98274818 0.98274818 0.98274818]\n",
      " [0.92235136 0.92235136 0.92235136 0.92235136 0.92235136 0.92235136]\n",
      " [0.96222996 0.96222996 0.96222996 0.96222996 0.96222996 0.96222996]\n",
      " [0.96131402 0.96131402 0.96131402 0.96131402 0.96131402 0.96131402]\n",
      " [0.98532567 0.98532567 0.98532567 0.98532567 0.98532567 0.98532567]\n",
      " [0.98123602 0.98123602 0.98123602 0.98123602 0.98123602 0.98123602]\n",
      " [0.99121193 0.99121193 0.99121193 0.99121193 0.99121193 0.99121193]\n",
      " [0.95928914 0.95928914 0.95928914 0.95928914 0.95928914 0.95928914]\n",
      " [0.99135204 0.99135204 0.99135204 0.99135204 0.99135204 0.99135204]\n",
      " [0.98697032 0.98697032 0.98697032 0.98697032 0.98697032 0.98697032]\n",
      " [0.98110177 0.98110177 0.98110177 0.98110177 0.98110177 0.98110177]\n",
      " [0.98169189 0.98169189 0.98169189 0.98169189 0.98169189 0.98169189]\n",
      " [0.99246067 0.99246067 0.99246067 0.99246067 0.99246067 0.99246067]]\n",
      "[[5.37507021 5.37507021 5.37507021 5.37507021 5.37507021 5.37507021]\n",
      " [5.34198877 5.34198877 5.34198877 5.34198877 5.34198877 5.34198877]\n",
      " [4.89026492 4.89026492 4.89026492 4.89026492 4.89026492 4.89026492]\n",
      " [4.88577788 4.88577788 4.88577788 4.88577788 4.88577788 4.88577788]\n",
      " [4.80253282 4.80253282 4.80253282 4.80253282 4.80253282 4.80253282]\n",
      " [4.79880116 4.79880116 4.79880116 4.79880116 4.79880116 4.79880116]\n",
      " [3.99713872 3.99713872 3.99713872 3.99713872 3.99713872 3.99713872]\n",
      " [4.04243528 4.04243528 4.04243528 4.04243528 4.04243528 4.04243528]\n",
      " [2.47473224 2.47473224 2.47473224 2.47473224 2.47473224 2.47473224]\n",
      " [3.23773721 3.23773721 3.23773721 3.23773721 3.23773721 3.23773721]\n",
      " [3.21282393 3.21282393 3.21282393 3.21282393 3.21282393 3.21282393]\n",
      " [4.20687234 4.20687234 4.20687234 4.20687234 4.20687234 4.20687234]\n",
      " [3.95687386 3.95687386 3.95687386 3.95687386 3.95687386 3.95687386]\n",
      " [4.72553349 4.72553349 4.72553349 4.72553349 4.72553349 4.72553349]\n",
      " [3.15969766 3.15969766 3.15969766 3.15969766 3.15969766 3.15969766]\n",
      " [4.74174661 4.74174661 4.74174661 4.74174661 4.74174661 4.74174661]\n",
      " [4.32741004 4.32741004 4.32741004 4.32741004 4.32741004 4.32741004]\n",
      " [3.94960802 3.94960802 3.94960802 3.94960802 3.94960802 3.94960802]\n",
      " [3.98193358 3.98193358 3.98193358 3.98193358 3.98193358 3.98193358]\n",
      " [4.88005386 4.88005386 4.88005386 4.88005386 4.88005386 4.88005386]]\n",
      "Layer Outputs\n",
      "[[5.91262105 5.91262105 5.91262105 5.91262105]\n",
      " [5.91170456 5.91170456 5.91170456 5.91170456]\n",
      " [5.89566794 5.89566794 5.89566794 5.89566794]\n",
      " [5.89547006 5.89547006 5.89547006 5.89547006]\n",
      " [5.89163598 5.89163598 5.89163598 5.89163598]\n",
      " [5.89145664 5.89145664 5.89145664 5.89145664]\n",
      " [5.8328613  5.8328613  5.8328613  5.8328613 ]\n",
      " [5.83752419 5.83752419 5.83752419 5.83752419]\n",
      " [5.47876709 5.47876709 5.47876709 5.47876709]\n",
      " [5.71564595 5.71564595 5.71564595 5.71564595]\n",
      " [5.71020529 5.71020529 5.71020529 5.71020529]\n",
      " [5.85283447 5.85283447 5.85283447 5.85283447]\n",
      " [5.82854195 5.82854195 5.82854195 5.82854195]\n",
      " [5.88779888 5.88779888 5.88779888 5.88779888]\n",
      " [5.6981775  5.6981775  5.6981775  5.6981775 ]\n",
      " [5.88863114 5.88863114 5.88863114 5.88863114]\n",
      " [5.86260369 5.86260369 5.86260369 5.86260369]\n",
      " [5.82774452 5.82774452 5.82774452 5.82774452]\n",
      " [5.83124985 5.83124985 5.83124985 5.83124985]\n",
      " [5.89521637 5.89521637 5.89521637 5.89521637]]\n",
      "[[5.91262105 5.91262105 5.91262105 5.91262105]\n",
      " [5.91170456 5.91170456 5.91170456 5.91170456]\n",
      " [5.89566794 5.89566794 5.89566794 5.89566794]\n",
      " [5.89547006 5.89547006 5.89547006 5.89547006]\n",
      " [5.89163598 5.89163598 5.89163598 5.89163598]\n",
      " [5.89145664 5.89145664 5.89145664 5.89145664]\n",
      " [5.8328613  5.8328613  5.8328613  5.8328613 ]\n",
      " [5.83752419 5.83752419 5.83752419 5.83752419]\n",
      " [5.47876709 5.47876709 5.47876709 5.47876709]\n",
      " [5.71564595 5.71564595 5.71564595 5.71564595]\n",
      " [5.71020529 5.71020529 5.71020529 5.71020529]\n",
      " [5.85283447 5.85283447 5.85283447 5.85283447]\n",
      " [5.82854195 5.82854195 5.82854195 5.82854195]\n",
      " [5.88779888 5.88779888 5.88779888 5.88779888]\n",
      " [5.6981775  5.6981775  5.6981775  5.6981775 ]\n",
      " [5.88863114 5.88863114 5.88863114 5.88863114]\n",
      " [5.86260369 5.86260369 5.86260369 5.86260369]\n",
      " [5.82774452 5.82774452 5.82774452 5.82774452]\n",
      " [5.83124985 5.83124985 5.83124985 5.83124985]\n",
      " [5.89521637 5.89521637 5.89521637 5.89521637]]\n",
      "Layer Outputs\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[[23.41397938 23.41397938]\n",
      " [23.41035005 23.41035005]\n",
      " [23.34684503 23.34684503]\n",
      " [23.34606146 23.34606146]\n",
      " [23.33087848 23.33087848]\n",
      " [23.3301683  23.3301683 ]\n",
      " [23.09813076 23.09813076]\n",
      " [23.1165958  23.1165958 ]\n",
      " [21.69591769 21.69591769]\n",
      " [22.63395796 22.63395796]\n",
      " [22.61241296 22.61241296]\n",
      " [23.17722448 23.17722448]\n",
      " [23.08102612 23.08102612]\n",
      " [23.31568355 23.31568355]\n",
      " [22.56478289 22.56478289]\n",
      " [23.3189793  23.3189793 ]\n",
      " [23.21591063 23.21591063]\n",
      " [23.07786831 23.07786831]\n",
      " [23.0917494  23.0917494 ]\n",
      " [23.34505683 23.34505683]]\n",
      "Delta Last\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.0044967  -0.0044967  -0.0044967  -0.0044967  -0.0044967  -0.0044967 ]\n",
      " [-0.00464651 -0.00464651 -0.00464651 -0.00464651 -0.00464651 -0.00464651]\n",
      " [-0.0072602  -0.0072602  -0.0072602  -0.0072602  -0.0072602  -0.0072602 ]\n",
      " [-0.00729236 -0.00729236 -0.00729236 -0.00729236 -0.00729236 -0.00729236]\n",
      " [-0.00791509 -0.00791509 -0.00791509 -0.00791509 -0.00791509 -0.00791509]\n",
      " [-0.0079442  -0.0079442  -0.0079442  -0.0079442  -0.0079442  -0.0079442 ]\n",
      " [-0.01735903 -0.01735903 -0.01735903 -0.01735903 -0.01735903 -0.01735903]\n",
      " [-0.01661681 -0.01661681 -0.01661681 -0.01661681 -0.01661681 -0.01661681]\n",
      " [-0.0701941  -0.0701941  -0.0701941  -0.0701941  -0.0701941  -0.0701941 ]\n",
      " [-0.03562023 -0.03562023 -0.03562023 -0.03562023 -0.03562023 -0.03562023]\n",
      " [-0.0364493  -0.0364493  -0.0364493  -0.0364493  -0.0364493  -0.0364493 ]\n",
      " [-0.01417126 -0.01417126 -0.01417126 -0.01417126 -0.01417126 -0.01417126]\n",
      " [-0.0180455  -0.0180455  -0.0180455  -0.0180455  -0.0180455  -0.0180455 ]\n",
      " [-0.00853749 -0.00853749 -0.00853749 -0.00853749 -0.00853749 -0.00853749]\n",
      " [-0.03827632 -0.03827632 -0.03827632 -0.03827632 -0.03827632 -0.03827632]\n",
      " [-0.00840256 -0.00840256 -0.00840256 -0.00840256 -0.00840256 -0.00840256]\n",
      " [-0.012604   -0.012604   -0.012604   -0.012604   -0.012604   -0.012604  ]\n",
      " [-0.01817212 -0.01817212 -0.01817212 -0.01817212 -0.01817212 -0.01817212]\n",
      " [-0.01761526 -0.01761526 -0.01761526 -0.01761526 -0.01761526 -0.01761526]\n",
      " [-0.00733359 -0.00733359 -0.00733359 -0.00733359 -0.00733359 -0.00733359]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]\n",
      " [-0.2475 -0.2475 -0.2475 -0.2475]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Learned\n",
      "0\n",
      "[1.79476314e-05 1.79476314e-05 1.79476314e-05 1.79476314e-05\n",
      " 1.79476314e-05 1.79476314e-05]\n",
      "0\n",
      "Weights\n",
      "[[0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]\n",
      " [0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]\n",
      " [0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]\n",
      " [0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]\n",
      " [0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]\n",
      " [0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]]\n",
      "Learned\n",
      "1\n",
      "[0.0002475 0.0002475 0.0002475 0.0002475]\n",
      "1\n",
      "Weights\n",
      "[[0.9902428 0.9902428 0.9902428 0.9902428 0.9902428 0.9902428]\n",
      " [0.9902428 0.9902428 0.9902428 0.9902428 0.9902428 0.9902428]\n",
      " [0.9902428 0.9902428 0.9902428 0.9902428 0.9902428 0.9902428]\n",
      " [0.9902428 0.9902428 0.9902428 0.9902428 0.9902428 0.9902428]]\n",
      "Learned\n",
      "2\n",
      "[0.000125 0.000125]\n",
      "2\n",
      "Weights\n",
      "[[0.99072841 0.99072841 0.99072841 0.99072841]\n",
      " [0.99072841 0.99072841 0.99072841 0.99072841]]\n",
      "Epoches changed from initial?\n",
      "[[0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]\n",
      " [0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]\n",
      " [0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]\n",
      " [0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]\n",
      " [0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]\n",
      " [0.99000839 0.99000934 0.99000716 0.99000595 0.99000838 0.99000816\n",
      "  0.99000798 0.99001045]]\n",
      "[1.79476314e-05 1.79476314e-05 1.79476314e-05 1.79476314e-05\n",
      " 1.79476314e-05 1.79476314e-05]\n",
      "Epoches changed from initial?\n",
      "[[0.9902428 0.9902428 0.9902428 0.9902428 0.9902428 0.9902428]\n",
      " [0.9902428 0.9902428 0.9902428 0.9902428 0.9902428 0.9902428]\n",
      " [0.9902428 0.9902428 0.9902428 0.9902428 0.9902428 0.9902428]\n",
      " [0.9902428 0.9902428 0.9902428 0.9902428 0.9902428 0.9902428]]\n",
      "[0.0002475 0.0002475 0.0002475 0.0002475]\n",
      "Epoches changed from initial?\n",
      "[[0.99072841 0.99072841 0.99072841 0.99072841]\n",
      " [0.99072841 0.99072841 0.99072841 0.99072841]]\n",
      "[0.000125 0.000125]\n",
      "Layer Outputs\n",
      "[[0.98274906 0.98274906 0.98274906 0.98274906 0.98274906 0.98274906]\n",
      " [0.96131574 0.96131574 0.96131574 0.96131574 0.96131574 0.96131574]\n",
      " [0.98532645 0.98532645 0.98532645 0.98532645 0.98532645 0.98532645]\n",
      " [0.99135256 0.99135256 0.99135256 0.99135256 0.99135256 0.99135256]\n",
      " [0.9924611  0.9924611  0.9924611  0.9924611  0.9924611  0.9924611 ]\n",
      " [0.96223163 0.96223163 0.96223163 0.96223163 0.96223163 0.96223163]\n",
      " [0.9819641  0.9819641  0.9819641  0.9819641  0.9819641  0.9819641 ]\n",
      " [0.98110275 0.98110275 0.98110275 0.98110275 0.98110275 0.98110275]\n",
      " [0.981237   0.981237   0.981237   0.981237   0.981237   0.981237  ]\n",
      " [0.92235409 0.92235409 0.92235409 0.92235409 0.92235409 0.92235409]\n",
      " [0.99182819 0.99182819 0.99182819 0.99182819 0.99182819 0.99182819]\n",
      " [0.99250382 0.99250382 0.99250382 0.99250382 0.99250382 0.99250382]\n",
      " [0.99121243 0.99121243 0.99121243 0.99121243 0.99121243 0.99121243]\n",
      " [0.99185836 0.99185836 0.99185836 0.99185836 0.99185836 0.99185836]\n",
      " [0.99523675 0.99523675 0.99523675 0.99523675 0.99523675 0.99523675]\n",
      " [0.99539104 0.99539104 0.99539104 0.99539104 0.99539104 0.99539104]\n",
      " [0.99253713 0.99253713 0.99253713 0.99253713 0.99253713 0.99253713]\n",
      " [0.9592909  0.9592909  0.9592909  0.9592909  0.9592909  0.9592909 ]\n",
      " [0.98697103 0.98697103 0.98697103 0.98697103 0.98697103 0.98697103]\n",
      " [0.98169283 0.98169283 0.98169283 0.98169283 0.98169283 0.98169283]]\n",
      "[[4.04248689 4.04248689 4.04248689 4.04248689 4.04248689 4.04248689]\n",
      " [3.21287015 3.21287015 3.21287015 3.21287015 3.21287015 3.21287015]\n",
      " [4.20692646 4.20692646 4.20692646 4.20692646 4.20692646 4.20692646]\n",
      " [4.74180655 4.74180655 4.74180655 4.74180655 4.74180655 4.74180655]\n",
      " [4.88011113 4.88011113 4.88011113 4.88011113 4.88011113 4.88011113]\n",
      " [3.23778313 3.23778313 3.23778313 3.23778313 3.23778313 3.23778313]\n",
      " [3.9971907  3.9971907  3.9971907  3.9971907  3.9971907  3.9971907 ]\n",
      " [3.94966088 3.94966088 3.94966088 3.94966088 3.94966088 3.94966088]\n",
      " [3.95692726 3.95692726 3.95692726 3.95692726 3.95692726 3.95692726]\n",
      " [2.47477029 2.47477029 2.47477029 2.47477029 2.47477029 2.47477029]\n",
      " [4.79885932 4.79885932 4.79885932 4.79885932 4.79885932 4.79885932]\n",
      " [4.88583705 4.88583705 4.88583705 4.88583705 4.88583705 4.88583705]\n",
      " [4.72559109 4.72559109 4.72559109 4.72559109 4.72559109 4.72559109]\n",
      " [4.80258848 4.80258848 4.80258848 4.80258848 4.80258848 4.80258848]\n",
      " [5.34205055 5.34205055 5.34205055 5.34205055 5.34205055 5.34205055]\n",
      " [5.37513297 5.37513297 5.37513297 5.37513297 5.37513297 5.37513297]\n",
      " [4.89032456 4.89032456 4.89032456 4.89032456 4.89032456 4.89032456]\n",
      " [3.15974266 3.15974266 3.15974266 3.15974266 3.15974266 3.15974266]\n",
      " [4.32746511 4.32746511 4.32746511 4.32746511 4.32746511 4.32746511]\n",
      " [3.98198559 3.98198559 3.98198559 3.98198559 3.98198559 3.98198559]]\n",
      "Layer Outputs\n",
      "[[5.83920859 5.83920859 5.83920859 5.83920859]\n",
      " [5.71186348 5.71186348 5.71186348 5.71186348]\n",
      " [5.85452207 5.85452207 5.85452207 5.85452207]\n",
      " [5.89032592 5.89032592 5.89032592 5.89032592]\n",
      " [5.89691226 5.89691226 5.89691226 5.89691226]\n",
      " [5.71730517 5.71730517 5.71730517 5.71730517]\n",
      " [5.83454483 5.83454483 5.83454483 5.83454483]\n",
      " [5.82942715 5.82942715 5.82942715 5.82942715]\n",
      " [5.83022478 5.83022478 5.83022478 5.83022478]\n",
      " [5.48037449 5.48037449 5.48037449 5.48037449]\n",
      " [5.89315187 5.89315187 5.89315187 5.89315187]\n",
      " [5.89716609 5.89716609 5.89716609 5.89716609]\n",
      " [5.88949338 5.88949338 5.88949338 5.88949338]\n",
      " [5.89333112 5.89333112 5.89333112 5.89333112]\n",
      " [5.91340369 5.91340369 5.91340369 5.91340369]\n",
      " [5.91432038 5.91432038 5.91432038 5.91432038]\n",
      " [5.89736402 5.89736402 5.89736402 5.89736402]\n",
      " [5.69983296 5.69983296 5.69983296 5.69983296]\n",
      " [5.86429325 5.86429325 5.86429325 5.86429325]\n",
      " [5.83293306 5.83293306 5.83293306 5.83293306]]\n",
      "[[5.83920859 5.83920859 5.83920859 5.83920859]\n",
      " [5.71186348 5.71186348 5.71186348 5.71186348]\n",
      " [5.85452207 5.85452207 5.85452207 5.85452207]\n",
      " [5.89032592 5.89032592 5.89032592 5.89032592]\n",
      " [5.89691226 5.89691226 5.89691226 5.89691226]\n",
      " [5.71730517 5.71730517 5.71730517 5.71730517]\n",
      " [5.83454483 5.83454483 5.83454483 5.83454483]\n",
      " [5.82942715 5.82942715 5.82942715 5.82942715]\n",
      " [5.83022478 5.83022478 5.83022478 5.83022478]\n",
      " [5.48037449 5.48037449 5.48037449 5.48037449]\n",
      " [5.89315187 5.89315187 5.89315187 5.89315187]\n",
      " [5.89716609 5.89716609 5.89716609 5.89716609]\n",
      " [5.88949338 5.88949338 5.88949338 5.88949338]\n",
      " [5.89333112 5.89333112 5.89333112 5.89333112]\n",
      " [5.91340369 5.91340369 5.91340369 5.91340369]\n",
      " [5.91432038 5.91432038 5.91432038 5.91432038]\n",
      " [5.89736402 5.89736402 5.89736402 5.89736402]\n",
      " [5.69983296 5.69983296 5.69983296 5.69983296]\n",
      " [5.86429325 5.86429325 5.86429325 5.86429325]\n",
      " [5.83293306 5.83293306 5.83293306 5.83293306]]\n",
      "Layer Outputs\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[[23.14040446 23.14040446]\n",
      " [22.63574679 22.63574679]\n",
      " [23.20109046 23.20109046]\n",
      " [23.34297804 23.34297804]\n",
      " [23.36907915 23.36907915]\n",
      " [22.65731175 22.65731175]\n",
      " [23.12192238 23.12192238]\n",
      " [23.10164146 23.10164146]\n",
      " [23.10480243 23.10480243]\n",
      " [21.71837594 21.71837594]\n",
      " [23.35417702 23.35417702]\n",
      " [23.37008504 23.37008504]\n",
      " [23.33967878 23.33967878]\n",
      " [23.35488738 23.35488738]\n",
      " [23.43443325 23.43443325]\n",
      " [23.43806602 23.43806602]\n",
      " [23.37086942 23.37086942]\n",
      " [22.58807088 22.58807088]\n",
      " [23.23981281 23.23981281]\n",
      " [23.1155351  23.1155351 ]]\n",
      "Delta Last\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.01663228 -0.01663228 -0.01663228 -0.01663228 -0.01663228 -0.01663228]\n",
      " [-0.03648351 -0.03648351 -0.03648351 -0.03648351 -0.03648351 -0.03648351]\n",
      " [-0.01418442 -0.01418442 -0.01418442 -0.01418442 -0.01418442 -0.01418442]\n",
      " [-0.00841031 -0.00841031 -0.00841031 -0.00841031 -0.00841031 -0.00841031]\n",
      " [-0.00734037 -0.00734037 -0.00734037 -0.00734037 -0.00734037 -0.00734037]\n",
      " [-0.03565367 -0.03565367 -0.03565367 -0.03565367 -0.03565367 -0.03565367]\n",
      " [-0.01737519 -0.01737519 -0.01737519 -0.01737519 -0.01737519 -0.01737519]\n",
      " [-0.01818902 -0.01818902 -0.01818902 -0.01818902 -0.01818902 -0.01818902]\n",
      " [-0.01806228 -0.01806228 -0.01806228 -0.01806228 -0.01806228 -0.01806228]\n",
      " [-0.07026072 -0.07026072 -0.07026072 -0.07026072 -0.07026072 -0.07026072]\n",
      " [-0.00795154 -0.00795154 -0.00795154 -0.00795154 -0.00795154 -0.00795154]\n",
      " [-0.00729909 -0.00729909 -0.00729909 -0.00729909 -0.00729909 -0.00729909]\n",
      " [-0.00854539 -0.00854539 -0.00854539 -0.00854539 -0.00854539 -0.00854539]\n",
      " [-0.00792242 -0.00792242 -0.00792242 -0.00792242 -0.00792242 -0.00792242]\n",
      " [-0.00465078 -0.00465078 -0.00465078 -0.00465078 -0.00465078 -0.00465078]\n",
      " [-0.00450084 -0.00450084 -0.00450084 -0.00450084 -0.00450084 -0.00450084]\n",
      " [-0.00726689 -0.00726689 -0.00726689 -0.00726689 -0.00726689 -0.00726689]\n",
      " [-0.03831229 -0.03831229 -0.03831229 -0.03831229 -0.03831229 -0.03831229]\n",
      " [-0.01261569 -0.01261569 -0.01261569 -0.01261569 -0.01261569 -0.01261569]\n",
      " [-0.01763166 -0.01763166 -0.01763166 -0.01763166 -0.01763166 -0.01763166]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]\n",
      " [-0.2476821 -0.2476821 -0.2476821 -0.2476821]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Learned\n",
      "0\n",
      "[3.59120497e-05 3.59120497e-05 3.59120497e-05 3.59120497e-05\n",
      " 3.59120497e-05 3.59120497e-05]\n",
      "0\n",
      "Weights\n",
      "[[0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]\n",
      " [0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]\n",
      " [0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]\n",
      " [0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]\n",
      " [0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]\n",
      " [0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]]\n",
      "Learned\n",
      "1\n",
      "[0.00049518 0.00049518 0.00049518 0.00049518]\n",
      "1\n",
      "Weights\n",
      "[[0.99048579 0.99048579 0.99048579 0.99048579 0.99048579 0.99048579]\n",
      " [0.99048579 0.99048579 0.99048579 0.99048579 0.99048579 0.99048579]\n",
      " [0.99048579 0.99048579 0.99048579 0.99048579 0.99048579 0.99048579]\n",
      " [0.99048579 0.99048579 0.99048579 0.99048579 0.99048579 0.99048579]]\n",
      "Learned\n",
      "2\n",
      "[0.00025 0.00025]\n",
      "2\n",
      "Weights\n",
      "[[0.99145704 0.99145704 0.99145704 0.99145704]\n",
      " [0.99145704 0.99145704 0.99145704 0.99145704]]\n",
      "Epoches changed from initial?\n",
      "[[0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]\n",
      " [0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]\n",
      " [0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]\n",
      " [0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]\n",
      " [0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]\n",
      " [0.9900168  0.99001869 0.99001434 0.99001191 0.99001676 0.99001633\n",
      "  0.99001597 0.99002092]]\n",
      "[3.59120497e-05 3.59120497e-05 3.59120497e-05 3.59120497e-05\n",
      " 3.59120497e-05 3.59120497e-05]\n",
      "Epoches changed from initial?\n",
      "[[0.99048579 0.99048579 0.99048579 0.99048579 0.99048579 0.99048579]\n",
      " [0.99048579 0.99048579 0.99048579 0.99048579 0.99048579 0.99048579]\n",
      " [0.99048579 0.99048579 0.99048579 0.99048579 0.99048579 0.99048579]\n",
      " [0.99048579 0.99048579 0.99048579 0.99048579 0.99048579 0.99048579]]\n",
      "[0.00049518 0.00049518 0.00049518 0.00049518]\n",
      "Epoches changed from initial?\n",
      "[[0.99145704 0.99145704 0.99145704 0.99145704]\n",
      " [0.99145704 0.99145704 0.99145704 0.99145704]]\n",
      "[0.00025 0.00025]\n",
      "Layer Outputs\n",
      "[[0.98110373 0.98110373 0.98110373 0.98110373 0.98110373 0.98110373]\n",
      " [0.98169376 0.98169376 0.98169376 0.98169376 0.98169376 0.98169376]\n",
      " [0.99539133 0.99539133 0.99539133 0.99539133 0.99539133 0.99539133]\n",
      " [0.99523704 0.99523704 0.99523704 0.99523704 0.99523704 0.99523704]\n",
      " [0.99121294 0.99121294 0.99121294 0.99121294 0.99121294 0.99121294]\n",
      " [0.99246153 0.99246153 0.99246153 0.99246153 0.99246153 0.99246153]\n",
      " [0.98123799 0.98123799 0.98123799 0.98123799 0.98123799 0.98123799]\n",
      " [0.95929266 0.95929266 0.95929266 0.95929266 0.95929266 0.95929266]\n",
      " [0.92235682 0.92235682 0.92235682 0.92235682 0.92235682 0.92235682]\n",
      " [0.98532723 0.98532723 0.98532723 0.98532723 0.98532723 0.98532723]\n",
      " [0.96131746 0.96131746 0.96131746 0.96131746 0.96131746 0.96131746]\n",
      " [0.99185881 0.99185881 0.99185881 0.99185881 0.99185881 0.99185881]\n",
      " [0.9622333  0.9622333  0.9622333  0.9622333  0.9622333  0.9622333 ]\n",
      " [0.98196502 0.98196502 0.98196502 0.98196502 0.98196502 0.98196502]\n",
      " [0.99182866 0.99182866 0.99182866 0.99182866 0.99182866 0.99182866]\n",
      " [0.99253757 0.99253757 0.99253757 0.99253757 0.99253757 0.99253757]\n",
      " [0.98697174 0.98697174 0.98697174 0.98697174 0.98697174 0.98697174]\n",
      " [0.99250426 0.99250426 0.99250426 0.99250426 0.99250426 0.99250426]\n",
      " [0.99135307 0.99135307 0.99135307 0.99135307 0.99135307 0.99135307]\n",
      " [0.98274993 0.98274993 0.98274993 0.98274993 0.98274993 0.98274993]]\n",
      "[[3.94971379 3.94971379 3.94971379 3.94971379 3.94971379 3.94971379]\n",
      " [3.98203765 3.98203765 3.98203765 3.98203765 3.98203765 3.98203765]\n",
      " [5.37519579 5.37519579 5.37519579 5.37519579 5.37519579 5.37519579]\n",
      " [5.34211239 5.34211239 5.34211239 5.34211239 5.34211239 5.34211239]\n",
      " [4.72564875 4.72564875 4.72564875 4.72564875 4.72564875 4.72564875]\n",
      " [4.88016846 4.88016846 4.88016846 4.88016846 4.88016846 4.88016846]\n",
      " [3.95698071 3.95698071 3.95698071 3.95698071 3.95698071 3.95698071]\n",
      " [3.15978771 3.15978771 3.15978771 3.15978771 3.15978771 3.15978771]\n",
      " [2.47480838 2.47480838 2.47480838 2.47480838 2.47480838 2.47480838]\n",
      " [4.20698063 4.20698063 4.20698063 4.20698063 4.20698063 4.20698063]\n",
      " [3.21291641 3.21291641 3.21291641 3.21291641 3.21291641 3.21291641]\n",
      " [4.80264419 4.80264419 4.80264419 4.80264419 4.80264419 4.80264419]\n",
      " [3.2378291  3.2378291  3.2378291  3.2378291  3.2378291  3.2378291 ]\n",
      " [3.99724273 3.99724273 3.99724273 3.99724273 3.99724273 3.99724273]\n",
      " [4.79891754 4.79891754 4.79891754 4.79891754 4.79891754 4.79891754]\n",
      " [4.89038427 4.89038427 4.89038427 4.89038427 4.89038427 4.89038427]\n",
      " [4.32752022 4.32752022 4.32752022 4.32752022 4.32752022 4.32752022]\n",
      " [4.88589627 4.88589627 4.88589627 4.88589627 4.88589627 4.88589627]\n",
      " [4.74186654 4.74186654 4.74186654 4.74186654 4.74186654 4.74186654]\n",
      " [4.04253855 4.04253855 4.04253855 4.04253855 4.04253855 4.04253855]]\n",
      "Layer Outputs\n",
      "[[5.83111101 5.83111101 5.83111101 5.83111101]\n",
      " [5.83461752 5.83461752 5.83461752 5.83461752]\n",
      " [5.91602096 5.91602096 5.91602096 5.91602096]\n",
      " [5.91510407 5.91510407 5.91510407 5.91510407]\n",
      " [5.89118914 5.89118914 5.89118914 5.89118914]\n",
      " [5.89860941 5.89860941 5.89860941 5.89860941]\n",
      " [5.83190886 5.83190886 5.83190886 5.83190886]\n",
      " [5.70148965 5.70148965 5.70148965 5.70148965]\n",
      " [5.48198309 5.48198309 5.48198309 5.48198309]\n",
      " [5.85621091 5.85621091 5.85621091 5.85621091]\n",
      " [5.71352289 5.71352289 5.71352289 5.71352289]\n",
      " [5.89502751 5.89502751 5.89502751 5.89502751]\n",
      " [5.71896562 5.71896562 5.71896562 5.71896562]\n",
      " [5.83622959 5.83622959 5.83622959 5.83622959]\n",
      " [5.89484834 5.89484834 5.89484834 5.89484834]\n",
      " [5.89906135 5.89906135 5.89906135 5.89906135]\n",
      " [5.86598405 5.86598405 5.86598405 5.86598405]\n",
      " [5.89886336 5.89886336 5.89886336 5.89886336]\n",
      " [5.89202195 5.89202195 5.89202195 5.89202195]\n",
      " [5.84089423 5.84089423 5.84089423 5.84089423]]\n",
      "[[5.83111101 5.83111101 5.83111101 5.83111101]\n",
      " [5.83461752 5.83461752 5.83461752 5.83461752]\n",
      " [5.91602096 5.91602096 5.91602096 5.91602096]\n",
      " [5.91510407 5.91510407 5.91510407 5.91510407]\n",
      " [5.89118914 5.89118914 5.89118914 5.89118914]\n",
      " [5.89860941 5.89860941 5.89860941 5.89860941]\n",
      " [5.83190886 5.83190886 5.83190886 5.83190886]\n",
      " [5.70148965 5.70148965 5.70148965 5.70148965]\n",
      " [5.48198309 5.48198309 5.48198309 5.48198309]\n",
      " [5.85621091 5.85621091 5.85621091 5.85621091]\n",
      " [5.71352289 5.71352289 5.71352289 5.71352289]\n",
      " [5.89502751 5.89502751 5.89502751 5.89502751]\n",
      " [5.71896562 5.71896562 5.71896562 5.71896562]\n",
      " [5.83622959 5.83622959 5.83622959 5.83622959]\n",
      " [5.89484834 5.89484834 5.89484834 5.89484834]\n",
      " [5.89906135 5.89906135 5.89906135 5.89906135]\n",
      " [5.86598405 5.86598405 5.86598405 5.86598405]\n",
      " [5.89886336 5.89886336 5.89886336 5.89886336]\n",
      " [5.89202195 5.89202195 5.89202195 5.89202195]\n",
      " [5.84089423 5.84089423 5.84089423 5.84089423]]\n",
      "Layer Outputs\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[[23.12543424 23.12543424]\n",
      " [23.13934044 23.13934044]\n",
      " [23.4621725  23.4621725 ]\n",
      " [23.45853629 23.45853629]\n",
      " [23.36369379 23.36369379]\n",
      " [23.39312128 23.39312128]\n",
      " [23.12859839 23.12859839]\n",
      " [22.61137819 22.61137819]\n",
      " [21.7408529  21.7408529 ]\n",
      " [23.22497614 23.22497614]\n",
      " [22.65909996 22.65909996]\n",
      " [23.37891608 23.37891608]\n",
      " [22.6806849  22.6806849 ]\n",
      " [23.14573366 23.14573366]\n",
      " [23.37820555 23.37820555]\n",
      " [23.39491362 23.39491362]\n",
      " [23.26373473 23.26373473]\n",
      " [23.39412843 23.39412843]\n",
      " [23.36699658 23.36699658]\n",
      " [23.16423279 23.16423279]]\n",
      "Delta Last\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.01820594 -0.01820594 -0.01820594 -0.01820594 -0.01820594 -0.01820594]\n",
      " [-0.01764807 -0.01764807 -0.01764807 -0.01764807 -0.01764807 -0.01764807]\n",
      " [-0.00450497 -0.00450497 -0.00450497 -0.00450497 -0.00450497 -0.00450497]\n",
      " [-0.00465506 -0.00465506 -0.00465506 -0.00465506 -0.00465506 -0.00465506]\n",
      " [-0.00855328 -0.00855328 -0.00855328 -0.00855328 -0.00855328 -0.00855328]\n",
      " [-0.00734716 -0.00734716 -0.00734716 -0.00734716 -0.00734716 -0.00734716]\n",
      " [-0.01807906 -0.01807906 -0.01807906 -0.01807906 -0.01807906 -0.01807906]\n",
      " [-0.03834829 -0.03834829 -0.03834829 -0.03834829 -0.03834829 -0.03834829]\n",
      " [-0.07032738 -0.07032738 -0.07032738 -0.07032738 -0.07032738 -0.07032738]\n",
      " [-0.01419759 -0.01419759 -0.01419759 -0.01419759 -0.01419759 -0.01419759]\n",
      " [-0.03651774 -0.03651774 -0.03651774 -0.03651774 -0.03651774 -0.03651774]\n",
      " [-0.00792976 -0.00792976 -0.00792976 -0.00792976 -0.00792976 -0.00792976]\n",
      " [-0.03568713 -0.03568713 -0.03568713 -0.03568713 -0.03568713 -0.03568713]\n",
      " [-0.01739137 -0.01739137 -0.01739137 -0.01739137 -0.01739137 -0.01739137]\n",
      " [-0.00795888 -0.00795888 -0.00795888 -0.00795888 -0.00795888 -0.00795888]\n",
      " [-0.0072736  -0.0072736  -0.0072736  -0.0072736  -0.0072736  -0.0072736 ]\n",
      " [-0.01262739 -0.01262739 -0.01262739 -0.01262739 -0.01262739 -0.01262739]\n",
      " [-0.00730582 -0.00730582 -0.00730582 -0.00730582 -0.00730582 -0.00730582]\n",
      " [-0.00841807 -0.00841807 -0.00841807 -0.00841807 -0.00841807 -0.00841807]\n",
      " [-0.01664777 -0.01664777 -0.01664777 -0.01664777 -0.01664777 -0.01664777]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]\n",
      " [-0.24786426 -0.24786426 -0.24786426 -0.24786426]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Learned\n",
      "0\n",
      "[5.38932662e-05 5.38932662e-05 5.38932662e-05 5.38932662e-05\n",
      " 5.38932662e-05 5.38932662e-05]\n",
      "0\n",
      "Weights\n",
      "[[0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]\n",
      " [0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]\n",
      " [0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]\n",
      " [0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]\n",
      " [0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]\n",
      " [0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]]\n",
      "Learned\n",
      "1\n",
      "[0.00074305 0.00074305 0.00074305 0.00074305]\n",
      "1\n",
      "Weights\n",
      "[[0.99072895 0.99072895 0.99072895 0.99072895 0.99072895 0.99072895]\n",
      " [0.99072895 0.99072895 0.99072895 0.99072895 0.99072895 0.99072895]\n",
      " [0.99072895 0.99072895 0.99072895 0.99072895 0.99072895 0.99072895]\n",
      " [0.99072895 0.99072895 0.99072895 0.99072895 0.99072895 0.99072895]]\n",
      "Learned\n",
      "2\n",
      "[0.000375 0.000375]\n",
      "2\n",
      "Weights\n",
      "[[0.99218588 0.99218588 0.99218588 0.99218588]\n",
      " [0.99218588 0.99218588 0.99218588 0.99218588]]\n",
      "Epoches changed from initial?\n",
      "[[0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]\n",
      " [0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]\n",
      " [0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]\n",
      " [0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]\n",
      " [0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]\n",
      " [0.99002521 0.99002804 0.99002151 0.99001788 0.99002516 0.99002451\n",
      "  0.99002396 0.99003139]]\n",
      "[5.38932662e-05 5.38932662e-05 5.38932662e-05 5.38932662e-05\n",
      " 5.38932662e-05 5.38932662e-05]\n",
      "Epoches changed from initial?\n",
      "[[0.99072895 0.99072895 0.99072895 0.99072895 0.99072895 0.99072895]\n",
      " [0.99072895 0.99072895 0.99072895 0.99072895 0.99072895 0.99072895]\n",
      " [0.99072895 0.99072895 0.99072895 0.99072895 0.99072895 0.99072895]\n",
      " [0.99072895 0.99072895 0.99072895 0.99072895 0.99072895 0.99072895]]\n",
      "[0.00074305 0.00074305 0.00074305 0.00074305]\n",
      "Epoches changed from initial?\n",
      "[[0.99218588 0.99218588 0.99218588 0.99218588]\n",
      " [0.99218588 0.99218588 0.99218588 0.99218588]]\n",
      "[0.000375 0.000375]\n",
      "Layer Outputs\n",
      "[[0.99539161 0.99539161 0.99539161 0.99539161 0.99539161 0.99539161]\n",
      " [0.99523734 0.99523734 0.99523734 0.99523734 0.99523734 0.99523734]\n",
      " [0.96131918 0.96131918 0.96131918 0.96131918 0.96131918 0.96131918]\n",
      " [0.98697245 0.98697245 0.98697245 0.98697245 0.98697245 0.98697245]\n",
      " [0.99185926 0.99185926 0.99185926 0.99185926 0.99185926 0.99185926]\n",
      " [0.98196595 0.98196595 0.98196595 0.98196595 0.98196595 0.98196595]\n",
      " [0.96223497 0.96223497 0.96223497 0.96223497 0.96223497 0.96223497]\n",
      " [0.99182913 0.99182913 0.99182913 0.99182913 0.99182913 0.99182913]\n",
      " [0.98110471 0.98110471 0.98110471 0.98110471 0.98110471 0.98110471]\n",
      " [0.95929442 0.95929442 0.95929442 0.95929442 0.95929442 0.95929442]\n",
      " [0.99246196 0.99246196 0.99246196 0.99246196 0.99246196 0.99246196]\n",
      " [0.99253802 0.99253802 0.99253802 0.99253802 0.99253802 0.99253802]\n",
      " [0.98123897 0.98123897 0.98123897 0.98123897 0.98123897 0.98123897]\n",
      " [0.99135359 0.99135359 0.99135359 0.99135359 0.99135359 0.99135359]\n",
      " [0.98275081 0.98275081 0.98275081 0.98275081 0.98275081 0.98275081]\n",
      " [0.98532802 0.98532802 0.98532802 0.98532802 0.98532802 0.98532802]\n",
      " [0.99121344 0.99121344 0.99121344 0.99121344 0.99121344 0.99121344]\n",
      " [0.9816947  0.9816947  0.9816947  0.9816947  0.9816947  0.9816947 ]\n",
      " [0.92235955 0.92235955 0.92235955 0.92235955 0.92235955 0.92235955]\n",
      " [0.9925047  0.9925047  0.9925047  0.9925047  0.9925047  0.9925047 ]]\n",
      "[[5.37525867 5.37525867 5.37525867 5.37525867 5.37525867 5.37525867]\n",
      " [5.34217428 5.34217428 5.34217428 5.34217428 5.34217428 5.34217428]\n",
      " [3.21296272 3.21296272 3.21296272 3.21296272 3.21296272 3.21296272]\n",
      " [4.32757539 4.32757539 4.32757539 4.32757539 4.32757539 4.32757539]\n",
      " [4.80269995 4.80269995 4.80269995 4.80269995 4.80269995 4.80269995]\n",
      " [3.9972948  3.9972948  3.9972948  3.9972948  3.9972948  3.9972948 ]\n",
      " [3.23787511 3.23787511 3.23787511 3.23787511 3.23787511 3.23787511]\n",
      " [4.79897582 4.79897582 4.79897582 4.79897582 4.79897582 4.79897582]\n",
      " [3.94976675 3.94976675 3.94976675 3.94976675 3.94976675 3.94976675]\n",
      " [3.15983279 3.15983279 3.15983279 3.15983279 3.15983279 3.15983279]\n",
      " [4.88022584 4.88022584 4.88022584 4.88022584 4.88022584 4.88022584]\n",
      " [4.89044403 4.89044403 4.89044403 4.89044403 4.89044403 4.89044403]\n",
      " [3.95703421 3.95703421 3.95703421 3.95703421 3.95703421 3.95703421]\n",
      " [4.74192659 4.74192659 4.74192659 4.74192659 4.74192659 4.74192659]\n",
      " [4.04259026 4.04259026 4.04259026 4.04259026 4.04259026 4.04259026]\n",
      " [4.20703486 4.20703486 4.20703486 4.20703486 4.20703486 4.20703486]\n",
      " [4.72570645 4.72570645 4.72570645 4.72570645 4.72570645 4.72570645]\n",
      " [3.98208976 3.98208976 3.98208976 3.98208976 3.98208976 3.98208976]\n",
      " [2.4748465  2.4748465  2.4748465  2.4748465  2.4748465  2.4748465 ]\n",
      " [4.88595555 4.88595555 4.88595555 4.88595555 4.88595555 4.88595555]]\n",
      "Layer Outputs\n",
      "[[5.91772279 5.91772279 5.91772279 5.91772279]\n",
      " [5.91680571 5.91680571 5.91680571 5.91680571]\n",
      " [5.71518353 5.71518353 5.71518353 5.71518353]\n",
      " [5.8676761  5.8676761  5.8676761  5.8676761 ]\n",
      " [5.89672514 5.89672514 5.89672514 5.89672514]\n",
      " [5.8379156  5.8379156  5.8379156  5.8379156 ]\n",
      " [5.7206273  5.7206273  5.7206273  5.7206273 ]\n",
      " [5.89654607 5.89654607 5.89654607 5.89654607]\n",
      " [5.83279612 5.83279612 5.83279612 5.83279612]\n",
      " [5.70314756 5.70314756 5.70314756 5.70314756]\n",
      " [5.9003078  5.9003078  5.9003078  5.9003078 ]\n",
      " [5.90075994 5.90075994 5.90075994 5.90075994]\n",
      " [5.83359418 5.83359418 5.83359418 5.83359418]\n",
      " [5.89371924 5.89371924 5.89371924 5.89371924]\n",
      " [5.84258111 5.84258111 5.84258111 5.84258111]\n",
      " [5.85790101 5.85790101 5.85790101 5.85790101]\n",
      " [5.89288615 5.89288615 5.89288615 5.89288615]\n",
      " [5.83630321 5.83630321 5.83630321 5.83630321]\n",
      " [5.48359288 5.48359288 5.48359288 5.48359288]\n",
      " [5.90056189 5.90056189 5.90056189 5.90056189]]\n",
      "[[5.91772279 5.91772279 5.91772279 5.91772279]\n",
      " [5.91680571 5.91680571 5.91680571 5.91680571]\n",
      " [5.71518353 5.71518353 5.71518353 5.71518353]\n",
      " [5.8676761  5.8676761  5.8676761  5.8676761 ]\n",
      " [5.89672514 5.89672514 5.89672514 5.89672514]\n",
      " [5.8379156  5.8379156  5.8379156  5.8379156 ]\n",
      " [5.7206273  5.7206273  5.7206273  5.7206273 ]\n",
      " [5.89654607 5.89654607 5.89654607 5.89654607]\n",
      " [5.83279612 5.83279612 5.83279612 5.83279612]\n",
      " [5.70314756 5.70314756 5.70314756 5.70314756]\n",
      " [5.9003078  5.9003078  5.9003078  5.9003078 ]\n",
      " [5.90075994 5.90075994 5.90075994 5.90075994]\n",
      " [5.83359418 5.83359418 5.83359418 5.83359418]\n",
      " [5.89371924 5.89371924 5.89371924 5.89371924]\n",
      " [5.84258111 5.84258111 5.84258111 5.84258111]\n",
      " [5.85790101 5.85790101 5.85790101 5.85790101]\n",
      " [5.89288615 5.89288615 5.89288615 5.89288615]\n",
      " [5.83630321 5.83630321 5.83630321 5.83630321]\n",
      " [5.48359288 5.48359288 5.48359288 5.48359288]\n",
      " [5.90056189 5.90056189 5.90056189 5.90056189]]\n",
      "Layer Outputs\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[[23.48629886 23.48629886]\n",
      " [23.48265919 23.48265919]\n",
      " [22.68247248 22.68247248]\n",
      " [23.28767638 23.28767638]\n",
      " [23.40296459 23.40296459]\n",
      " [23.1695646  23.1695646 ]\n",
      " [22.70407741 22.70407741]\n",
      " [23.40225388 23.40225388]\n",
      " [23.14924668 23.14924668]\n",
      " [22.63470482 22.63470482]\n",
      " [23.41718323 23.41718323]\n",
      " [23.41897764 23.41897764]\n",
      " [23.15241401 23.15241401]\n",
      " [23.39103492 23.39103492]\n",
      " [23.1880808  23.1880808 ]\n",
      " [23.24888154 23.24888154]\n",
      " [23.38772861 23.38772861]\n",
      " [23.16316545 23.16316545]\n",
      " [21.7633486  21.7633486 ]\n",
      " [23.41819164 23.41819164]]\n",
      "Delta Last\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.00450911 -0.00450911 -0.00450911 -0.00450911 -0.00450911 -0.00450911]\n",
      " [-0.00465934 -0.00465934 -0.00465934 -0.00465934 -0.00465934 -0.00465934]\n",
      " [-0.036552   -0.036552   -0.036552   -0.036552   -0.036552   -0.036552  ]\n",
      " [-0.01263909 -0.01263909 -0.01263909 -0.01263909 -0.01263909 -0.01263909]\n",
      " [-0.0079371  -0.0079371  -0.0079371  -0.0079371  -0.0079371  -0.0079371 ]\n",
      " [-0.01740755 -0.01740755 -0.01740755 -0.01740755 -0.01740755 -0.01740755]\n",
      " [-0.03572061 -0.03572061 -0.03572061 -0.03572061 -0.03572061 -0.03572061]\n",
      " [-0.00796623 -0.00796623 -0.00796623 -0.00796623 -0.00796623 -0.00796623]\n",
      " [-0.01822287 -0.01822287 -0.01822287 -0.01822287 -0.01822287 -0.01822287]\n",
      " [-0.03838431 -0.03838431 -0.03838431 -0.03838431 -0.03838431 -0.03838431]\n",
      " [-0.00735395 -0.00735395 -0.00735395 -0.00735395 -0.00735395 -0.00735395]\n",
      " [-0.0072803  -0.0072803  -0.0072803  -0.0072803  -0.0072803  -0.0072803 ]\n",
      " [-0.01809586 -0.01809586 -0.01809586 -0.01809586 -0.01809586 -0.01809586]\n",
      " [-0.00842583 -0.00842583 -0.00842583 -0.00842583 -0.00842583 -0.00842583]\n",
      " [-0.01666326 -0.01666326 -0.01666326 -0.01666326 -0.01666326 -0.01666326]\n",
      " [-0.01421077 -0.01421077 -0.01421077 -0.01421077 -0.01421077 -0.01421077]\n",
      " [-0.00856119 -0.00856119 -0.00856119 -0.00856119 -0.00856119 -0.00856119]\n",
      " [-0.01766449 -0.01766449 -0.01766449 -0.01766449 -0.01766449 -0.01766449]\n",
      " [-0.07039409 -0.07039409 -0.07039409 -0.07039409 -0.07039409 -0.07039409]\n",
      " [-0.00731256 -0.00731256 -0.00731256 -0.00731256 -0.00731256 -0.00731256]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]\n",
      " [-0.24804647 -0.24804647 -0.24804647 -0.24804647]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Learned\n",
      "0\n",
      "[7.1891292e-05 7.1891292e-05 7.1891292e-05 7.1891292e-05 7.1891292e-05\n",
      " 7.1891292e-05]\n",
      "0\n",
      "Weights\n",
      "[[0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]\n",
      " [0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]\n",
      " [0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]\n",
      " [0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]\n",
      " [0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]\n",
      " [0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]]\n",
      "Learned\n",
      "1\n",
      "[0.00099109 0.00099109 0.00099109 0.00099109]\n",
      "1\n",
      "Weights\n",
      "[[0.99097229 0.99097229 0.99097229 0.99097229 0.99097229 0.99097229]\n",
      " [0.99097229 0.99097229 0.99097229 0.99097229 0.99097229 0.99097229]\n",
      " [0.99097229 0.99097229 0.99097229 0.99097229 0.99097229 0.99097229]\n",
      " [0.99097229 0.99097229 0.99097229 0.99097229 0.99097229 0.99097229]]\n",
      "Learned\n",
      "2\n",
      "[0.0005 0.0005]\n",
      "2\n",
      "Weights\n",
      "[[0.99291492 0.99291492 0.99291492 0.99291492]\n",
      " [0.99291492 0.99291492 0.99291492 0.99291492]]\n",
      "Epoches changed from initial?\n",
      "[[0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]\n",
      " [0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]\n",
      " [0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]\n",
      " [0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]\n",
      " [0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]\n",
      " [0.99003363 0.99003741 0.9900287  0.99002385 0.99003356 0.99003269\n",
      "  0.99003196 0.99004188]]\n",
      "[7.1891292e-05 7.1891292e-05 7.1891292e-05 7.1891292e-05 7.1891292e-05\n",
      " 7.1891292e-05]\n",
      "Epoches changed from initial?\n",
      "[[0.99097229 0.99097229 0.99097229 0.99097229 0.99097229 0.99097229]\n",
      " [0.99097229 0.99097229 0.99097229 0.99097229 0.99097229 0.99097229]\n",
      " [0.99097229 0.99097229 0.99097229 0.99097229 0.99097229 0.99097229]\n",
      " [0.99097229 0.99097229 0.99097229 0.99097229 0.99097229 0.99097229]]\n",
      "[0.00099109 0.00099109 0.00099109 0.00099109]\n",
      "Epoches changed from initial?\n",
      "[[0.99291492 0.99291492 0.99291492 0.99291492]\n",
      " [0.99291492 0.99291492 0.99291492 0.99291492]]\n",
      "[0.0005 0.0005]\n",
      "Layer Outputs\n",
      "[[0.92236228 0.92236228 0.92236228 0.92236228 0.92236228 0.92236228]\n",
      " [0.95929618 0.95929618 0.95929618 0.95929618 0.95929618 0.95929618]\n",
      " [0.99250514 0.99250514 0.99250514 0.99250514 0.99250514 0.99250514]\n",
      " [0.98123996 0.98123996 0.98123996 0.98123996 0.98123996 0.98123996]\n",
      " [0.9853288  0.9853288  0.9853288  0.9853288  0.9853288  0.9853288 ]\n",
      " [0.98275168 0.98275168 0.98275168 0.98275168 0.98275168 0.98275168]\n",
      " [0.99246238 0.99246238 0.99246238 0.99246238 0.99246238 0.99246238]\n",
      " [0.99182961 0.99182961 0.99182961 0.99182961 0.99182961 0.99182961]\n",
      " [0.9811057  0.9811057  0.9811057  0.9811057  0.9811057  0.9811057 ]\n",
      " [0.9953919  0.9953919  0.9953919  0.9953919  0.9953919  0.9953919 ]\n",
      " [0.98697316 0.98697316 0.98697316 0.98697316 0.98697316 0.98697316]\n",
      " [0.99121394 0.99121394 0.99121394 0.99121394 0.99121394 0.99121394]\n",
      " [0.99523763 0.99523763 0.99523763 0.99523763 0.99523763 0.99523763]\n",
      " [0.99253846 0.99253846 0.99253846 0.99253846 0.99253846 0.99253846]\n",
      " [0.96132091 0.96132091 0.96132091 0.96132091 0.96132091 0.96132091]\n",
      " [0.98169564 0.98169564 0.98169564 0.98169564 0.98169564 0.98169564]\n",
      " [0.98196687 0.98196687 0.98196687 0.98196687 0.98196687 0.98196687]\n",
      " [0.99185971 0.99185971 0.99185971 0.99185971 0.99185971 0.99185971]\n",
      " [0.9913541  0.9913541  0.9913541  0.9913541  0.9913541  0.9913541 ]\n",
      " [0.96223664 0.96223664 0.96223664 0.96223664 0.96223664 0.96223664]]\n",
      "[[2.47488466 2.47488466 2.47488466 2.47488466 2.47488466 2.47488466]\n",
      " [3.15987792 3.15987792 3.15987792 3.15987792 3.15987792 3.15987792]\n",
      " [4.88601488 4.88601488 4.88601488 4.88601488 4.88601488 4.88601488]\n",
      " [3.95708776 3.95708776 3.95708776 3.95708776 3.95708776 3.95708776]\n",
      " [4.20708913 4.20708913 4.20708913 4.20708913 4.20708913 4.20708913]\n",
      " [4.04264201 4.04264201 4.04264201 4.04264201 4.04264201 4.04264201]\n",
      " [4.88028328 4.88028328 4.88028328 4.88028328 4.88028328 4.88028328]\n",
      " [4.79903415 4.79903415 4.79903415 4.79903415 4.79903415 4.79903415]\n",
      " [3.94981977 3.94981977 3.94981977 3.94981977 3.94981977 3.94981977]\n",
      " [5.3753216  5.3753216  5.3753216  5.3753216  5.3753216  5.3753216 ]\n",
      " [4.32763061 4.32763061 4.32763061 4.32763061 4.32763061 4.32763061]\n",
      " [4.72576422 4.72576422 4.72576422 4.72576422 4.72576422 4.72576422]\n",
      " [5.34223623 5.34223623 5.34223623 5.34223623 5.34223623 5.34223623]\n",
      " [4.89050384 4.89050384 4.89050384 4.89050384 4.89050384 4.89050384]\n",
      " [3.21300907 3.21300907 3.21300907 3.21300907 3.21300907 3.21300907]\n",
      " [3.98214191 3.98214191 3.98214191 3.98214191 3.98214191 3.98214191]\n",
      " [3.99734693 3.99734693 3.99734693 3.99734693 3.99734693 3.99734693]\n",
      " [4.80275576 4.80275576 4.80275576 4.80275576 4.80275576 4.80275576]\n",
      " [4.7419867  4.7419867  4.7419867  4.7419867  4.7419867  4.7419867 ]\n",
      " [3.23792117 3.23792117 3.23792117 3.23792117 3.23792117 3.23792117]]\n",
      "Layer Outputs\n",
      "[[5.48520387 5.48520387 5.48520387 5.48520387]\n",
      " [5.7048067  5.7048067  5.7048067  5.7048067 ]\n",
      " [5.90226167 5.90226167 5.90226167 5.90226167]\n",
      " [5.83528075 5.83528075 5.83528075 5.83528075]\n",
      " [5.85959235 5.85959235 5.85959235 5.85959235]\n",
      " [5.84426924 5.84426924 5.84426924 5.84426924]\n",
      " [5.90200744 5.90200744 5.90200744 5.90200744]\n",
      " [5.89824504 5.89824504 5.89824504 5.89824504]\n",
      " [5.83448247 5.83448247 5.83448247 5.83448247]\n",
      " [5.91942587 5.91942587 5.91942587 5.91942587]\n",
      " [5.8693694  5.8693694  5.8693694  5.8693694 ]\n",
      " [5.89458441 5.89458441 5.89458441 5.89458441]\n",
      " [5.91850859 5.91850859 5.91850859 5.91850859]\n",
      " [5.90245977 5.90245977 5.90245977 5.90245977]\n",
      " [5.7168454  5.7168454  5.7168454  5.7168454 ]\n",
      " [5.83799016 5.83799016 5.83799016 5.83799016]\n",
      " [5.83960286 5.83960286 5.83960286 5.83960286]\n",
      " [5.89842403 5.89842403 5.89842403 5.89842403]\n",
      " [5.89541777 5.89541777 5.89541777 5.89541777]\n",
      " [5.72229021 5.72229021 5.72229021 5.72229021]]\n",
      "[[5.48520387 5.48520387 5.48520387 5.48520387]\n",
      " [5.7048067  5.7048067  5.7048067  5.7048067 ]\n",
      " [5.90226167 5.90226167 5.90226167 5.90226167]\n",
      " [5.83528075 5.83528075 5.83528075 5.83528075]\n",
      " [5.85959235 5.85959235 5.85959235 5.85959235]\n",
      " [5.84426924 5.84426924 5.84426924 5.84426924]\n",
      " [5.90200744 5.90200744 5.90200744 5.90200744]\n",
      " [5.89824504 5.89824504 5.89824504 5.89824504]\n",
      " [5.83448247 5.83448247 5.83448247 5.83448247]\n",
      " [5.91942587 5.91942587 5.91942587 5.91942587]\n",
      " [5.8693694  5.8693694  5.8693694  5.8693694 ]\n",
      " [5.89458441 5.89458441 5.89458441 5.89458441]\n",
      " [5.91850859 5.91850859 5.91850859 5.91850859]\n",
      " [5.90245977 5.90245977 5.90245977 5.90245977]\n",
      " [5.7168454  5.7168454  5.7168454  5.7168454 ]\n",
      " [5.83799016 5.83799016 5.83799016 5.83799016]\n",
      " [5.83960286 5.83960286 5.83960286 5.83960286]\n",
      " [5.89842403 5.89842403 5.89842403 5.89842403]\n",
      " [5.89541777 5.89541777 5.89541777 5.89541777]\n",
      " [5.72229021 5.72229021 5.72229021 5.72229021]]\n",
      "Layer Outputs\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[[21.78586305 21.78586305]\n",
      " [22.65805079 22.65805079]\n",
      " [23.44227471 23.44227471]\n",
      " [23.1762493  23.1762493 ]\n",
      " [23.27280669 23.27280669]\n",
      " [23.21194851 23.21194851]\n",
      " [23.44126503 23.44126503]\n",
      " [23.42632205 23.42632205]\n",
      " [23.1730788  23.1730788 ]\n",
      " [23.5104451  23.5104451 ]\n",
      " [23.31163781 23.31163781]\n",
      " [23.41178325 23.41178325]\n",
      " [23.50680198 23.50680198]\n",
      " [23.44306151 23.44306151]\n",
      " [22.70586438 22.70586438]\n",
      " [23.18701014 23.18701014]\n",
      " [23.19341524 23.19341524]\n",
      " [23.42703294 23.42703294]\n",
      " [23.41509309 23.41509309]\n",
      " [22.72748932 22.72748932]]\n",
      "Delta Last\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.07046085 -0.07046085 -0.07046085 -0.07046085 -0.07046085 -0.07046085]\n",
      " [-0.03842036 -0.03842036 -0.03842036 -0.03842036 -0.03842036 -0.03842036]\n",
      " [-0.0073193  -0.0073193  -0.0073193  -0.0073193  -0.0073193  -0.0073193 ]\n",
      " [-0.01811268 -0.01811268 -0.01811268 -0.01811268 -0.01811268 -0.01811268]\n",
      " [-0.01422395 -0.01422395 -0.01422395 -0.01422395 -0.01422395 -0.01422395]\n",
      " [-0.01667877 -0.01667877 -0.01667877 -0.01667877 -0.01667877 -0.01667877]\n",
      " [-0.00736074 -0.00736074 -0.00736074 -0.00736074 -0.00736074 -0.00736074]\n",
      " [-0.00797359 -0.00797359 -0.00797359 -0.00797359 -0.00797359 -0.00797359]\n",
      " [-0.01823981 -0.01823981 -0.01823981 -0.01823981 -0.01823981 -0.01823981]\n",
      " [-0.00451325 -0.00451325 -0.00451325 -0.00451325 -0.00451325 -0.00451325]\n",
      " [-0.0126508  -0.0126508  -0.0126508  -0.0126508  -0.0126508  -0.0126508 ]\n",
      " [-0.0085691  -0.0085691  -0.0085691  -0.0085691  -0.0085691  -0.0085691 ]\n",
      " [-0.00466362 -0.00466362 -0.00466362 -0.00466362 -0.00466362 -0.00466362]\n",
      " [-0.00728701 -0.00728701 -0.00728701 -0.00728701 -0.00728701 -0.00728701]\n",
      " [-0.03658628 -0.03658628 -0.03658628 -0.03658628 -0.03658628 -0.03658628]\n",
      " [-0.01768093 -0.01768093 -0.01768093 -0.01768093 -0.01768093 -0.01768093]\n",
      " [-0.01742374 -0.01742374 -0.01742374 -0.01742374 -0.01742374 -0.01742374]\n",
      " [-0.00794445 -0.00794445 -0.00794445 -0.00794445 -0.00794445 -0.00794445]\n",
      " [-0.00843359 -0.00843359 -0.00843359 -0.00843359 -0.00843359 -0.00843359]\n",
      " [-0.03575412 -0.03575412 -0.03575412 -0.03575412 -0.03575412 -0.03575412]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]\n",
      " [-0.24822873 -0.24822873 -0.24822873 -0.24822873]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Learned\n",
      "0\n",
      "[8.99061385e-05 8.99061385e-05 8.99061385e-05 8.99061385e-05\n",
      " 8.99061385e-05 8.99061385e-05]\n",
      "0\n",
      "Weights\n",
      "[[0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]\n",
      " [0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]\n",
      " [0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]\n",
      " [0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]\n",
      " [0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]\n",
      " [0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]]\n",
      "Learned\n",
      "1\n",
      "[0.00123932 0.00123932 0.00123932 0.00123932]\n",
      "1\n",
      "Weights\n",
      "[[0.99121581 0.99121581 0.99121581 0.99121581 0.99121581 0.99121581]\n",
      " [0.99121581 0.99121581 0.99121581 0.99121581 0.99121581 0.99121581]\n",
      " [0.99121581 0.99121581 0.99121581 0.99121581 0.99121581 0.99121581]\n",
      " [0.99121581 0.99121581 0.99121581 0.99121581 0.99121581 0.99121581]]\n",
      "Learned\n",
      "2\n",
      "[0.000625 0.000625]\n",
      "2\n",
      "Weights\n",
      "[[0.99364418 0.99364418 0.99364418 0.99364418]\n",
      " [0.99364418 0.99364418 0.99364418 0.99364418]]\n",
      "Epoches changed from initial?\n",
      "[[0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]\n",
      " [0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]\n",
      " [0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]\n",
      " [0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]\n",
      " [0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]\n",
      " [0.99004205 0.99004678 0.99003589 0.99002983 0.99004197 0.99004088\n",
      "  0.99003997 0.99005237]]\n",
      "[8.99061385e-05 8.99061385e-05 8.99061385e-05 8.99061385e-05\n",
      " 8.99061385e-05 8.99061385e-05]\n",
      "Epoches changed from initial?\n",
      "[[0.99121581 0.99121581 0.99121581 0.99121581 0.99121581 0.99121581]\n",
      " [0.99121581 0.99121581 0.99121581 0.99121581 0.99121581 0.99121581]\n",
      " [0.99121581 0.99121581 0.99121581 0.99121581 0.99121581 0.99121581]\n",
      " [0.99121581 0.99121581 0.99121581 0.99121581 0.99121581 0.99121581]]\n",
      "[0.00123932 0.00123932 0.00123932 0.00123932]\n",
      "Epoches changed from initial?\n",
      "[[0.99364418 0.99364418 0.99364418 0.99364418]\n",
      " [0.99364418 0.99364418 0.99364418 0.99364418]]\n",
      "[0.000625 0.000625]\n",
      "Layer Outputs\n",
      "[[0.98110668 0.98110668 0.98110668 0.98110668 0.98110668 0.98110668]\n",
      " [0.99539219 0.99539219 0.99539219 0.99539219 0.99539219 0.99539219]\n",
      " [0.92236501 0.92236501 0.92236501 0.92236501 0.92236501 0.92236501]\n",
      " [0.99135462 0.99135462 0.99135462 0.99135462 0.99135462 0.99135462]\n",
      " [0.98124094 0.98124094 0.98124094 0.98124094 0.98124094 0.98124094]\n",
      " [0.99250558 0.99250558 0.99250558 0.99250558 0.99250558 0.99250558]\n",
      " [0.99121445 0.99121445 0.99121445 0.99121445 0.99121445 0.99121445]\n",
      " [0.99523792 0.99523792 0.99523792 0.99523792 0.99523792 0.99523792]\n",
      " [0.98169658 0.98169658 0.98169658 0.98169658 0.98169658 0.98169658]\n",
      " [0.99186016 0.99186016 0.99186016 0.99186016 0.99186016 0.99186016]\n",
      " [0.98532959 0.98532959 0.98532959 0.98532959 0.98532959 0.98532959]\n",
      " [0.98697387 0.98697387 0.98697387 0.98697387 0.98697387 0.98697387]\n",
      " [0.99246281 0.99246281 0.99246281 0.99246281 0.99246281 0.99246281]\n",
      " [0.96132263 0.96132263 0.96132263 0.96132263 0.96132263 0.96132263]\n",
      " [0.96223832 0.96223832 0.96223832 0.96223832 0.96223832 0.96223832]\n",
      " [0.98196779 0.98196779 0.98196779 0.98196779 0.98196779 0.98196779]\n",
      " [0.95929794 0.95929794 0.95929794 0.95929794 0.95929794 0.95929794]\n",
      " [0.9925389  0.9925389  0.9925389  0.9925389  0.9925389  0.9925389 ]\n",
      " [0.98275256 0.98275256 0.98275256 0.98275256 0.98275256 0.98275256]\n",
      " [0.99183008 0.99183008 0.99183008 0.99183008 0.99183008 0.99183008]]\n",
      "[[3.94987283 3.94987283 3.94987283 3.94987283 3.94987283 3.94987283]\n",
      " [5.37538459 5.37538459 5.37538459 5.37538459 5.37538459 5.37538459]\n",
      " [2.47492286 2.47492286 2.47492286 2.47492286 2.47492286 2.47492286]\n",
      " [4.74204686 4.74204686 4.74204686 4.74204686 4.74204686 4.74204686]\n",
      " [3.95714137 3.95714137 3.95714137 3.95714137 3.95714137 3.95714137]\n",
      " [4.88607427 4.88607427 4.88607427 4.88607427 4.88607427 4.88607427]\n",
      " [4.72582203 4.72582203 4.72582203 4.72582203 4.72582203 4.72582203]\n",
      " [5.34229824 5.34229824 5.34229824 5.34229824 5.34229824 5.34229824]\n",
      " [3.98219411 3.98219411 3.98219411 3.98219411 3.98219411 3.98219411]\n",
      " [4.80281162 4.80281162 4.80281162 4.80281162 4.80281162 4.80281162]\n",
      " [4.20714345 4.20714345 4.20714345 4.20714345 4.20714345 4.20714345]\n",
      " [4.32768588 4.32768588 4.32768588 4.32768588 4.32768588 4.32768588]\n",
      " [4.88034076 4.88034076 4.88034076 4.88034076 4.88034076 4.88034076]\n",
      " [3.21305546 3.21305546 3.21305546 3.21305546 3.21305546 3.21305546]\n",
      " [3.23796727 3.23796727 3.23796727 3.23796727 3.23796727 3.23796727]\n",
      " [3.9973991  3.9973991  3.9973991  3.9973991  3.9973991  3.9973991 ]\n",
      " [3.15992308 3.15992308 3.15992308 3.15992308 3.15992308 3.15992308]\n",
      " [4.89056372 4.89056372 4.89056372 4.89056372 4.89056372 4.89056372]\n",
      " [4.04269382 4.04269382 4.04269382 4.04269382 4.04269382 4.04269382]\n",
      " [4.79909253 4.79909253 4.79909253 4.79909253 4.79909253 4.79909253]]\n",
      "Layer Outputs\n",
      "[[5.83617006 5.83617006 5.83617006 5.83617006]\n",
      " [5.92113021 5.92113021 5.92113021 5.92113021]\n",
      " [5.48681605 5.48681605 5.48681605 5.48681605]\n",
      " [5.89711756 5.89711756 5.89711756 5.89711756]\n",
      " [5.83696856 5.83696856 5.83696856 5.83696856]\n",
      " [5.9039627  5.9039627  5.9039627  5.9039627 ]\n",
      " [5.89628392 5.89628392 5.89628392 5.89628392]\n",
      " [5.92021274 5.92021274 5.92021274 5.92021274]\n",
      " [5.83967834 5.83967834 5.83967834 5.83967834]\n",
      " [5.90012418 5.90012418 5.90012418 5.90012418]\n",
      " [5.86128493 5.86128493 5.86128493 5.86128493]\n",
      " [5.87106394 5.87106394 5.87106394 5.87106394]\n",
      " [5.90370834 5.90370834 5.90370834 5.90370834]\n",
      " [5.71850849 5.71850849 5.71850849 5.71850849]\n",
      " [5.72395435 5.72395435 5.72395435 5.72395435]\n",
      " [5.84129136 5.84129136 5.84129136 5.84129136]\n",
      " [5.70646707 5.70646707 5.70646707 5.70646707]\n",
      " [5.90416086 5.90416086 5.90416086 5.90416086]\n",
      " [5.84595861 5.84595861 5.84595861 5.84595861]\n",
      " [5.89994527 5.89994527 5.89994527 5.89994527]]\n",
      "[[5.83617006 5.83617006 5.83617006 5.83617006]\n",
      " [5.92113021 5.92113021 5.92113021 5.92113021]\n",
      " [5.48681605 5.48681605 5.48681605 5.48681605]\n",
      " [5.89711756 5.89711756 5.89711756 5.89711756]\n",
      " [5.83696856 5.83696856 5.83696856 5.83696856]\n",
      " [5.9039627  5.9039627  5.9039627  5.9039627 ]\n",
      " [5.89628392 5.89628392 5.89628392 5.89628392]\n",
      " [5.92021274 5.92021274 5.92021274 5.92021274]\n",
      " [5.83967834 5.83967834 5.83967834 5.83967834]\n",
      " [5.90012418 5.90012418 5.90012418 5.90012418]\n",
      " [5.86128493 5.86128493 5.86128493 5.86128493]\n",
      " [5.87106394 5.87106394 5.87106394 5.87106394]\n",
      " [5.90370834 5.90370834 5.90370834 5.90370834]\n",
      " [5.71850849 5.71850849 5.71850849 5.71850849]\n",
      " [5.72395435 5.72395435 5.72395435 5.72395435]\n",
      " [5.84129136 5.84129136 5.84129136 5.84129136]\n",
      " [5.70646707 5.70646707 5.70646707 5.70646707]\n",
      " [5.90416086 5.90416086 5.90416086 5.90416086]\n",
      " [5.84595861 5.84595861 5.84595861 5.84595861]\n",
      " [5.89994527 5.89994527 5.89994527 5.89994527]]\n",
      "Layer Outputs\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[[23.19693062 23.19693062]\n",
      " [23.53461124 23.53461124]\n",
      " [21.80839627 21.80839627]\n",
      " [23.43917112 23.43917112]\n",
      " [23.20010431 23.20010431]\n",
      " [23.46637763 23.46637763]\n",
      " [23.43585775 23.43585775]\n",
      " [23.53096467 23.53096467]\n",
      " [23.21087454 23.21087454]\n",
      " [23.45112114 23.45112114]\n",
      " [23.29675159 23.29675159]\n",
      " [23.33561901 23.33561901]\n",
      " [23.46536668 23.46536668]\n",
      " [22.72927568 22.72927568]\n",
      " [22.75092064 22.75092064]\n",
      " [23.21728558 23.21728558]\n",
      " [22.68141612 22.68141612]\n",
      " [23.46716525 23.46716525]\n",
      " [23.23583595 23.23583595]\n",
      " [23.45041008 23.45041008]]\n",
      "Delta Last\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.01825676 -0.01825676 -0.01825676 -0.01825676 -0.01825676 -0.01825676]\n",
      " [-0.00451739 -0.00451739 -0.00451739 -0.00451739 -0.00451739 -0.00451739]\n",
      " [-0.07052765 -0.07052765 -0.07052765 -0.07052765 -0.07052765 -0.07052765]\n",
      " [-0.00844136 -0.00844136 -0.00844136 -0.00844136 -0.00844136 -0.00844136]\n",
      " [-0.0181295  -0.0181295  -0.0181295  -0.0181295  -0.0181295  -0.0181295 ]\n",
      " [-0.00732605 -0.00732605 -0.00732605 -0.00732605 -0.00732605 -0.00732605]\n",
      " [-0.00857701 -0.00857701 -0.00857701 -0.00857701 -0.00857701 -0.00857701]\n",
      " [-0.00466791 -0.00466791 -0.00466791 -0.00466791 -0.00466791 -0.00466791]\n",
      " [-0.01769737 -0.01769737 -0.01769737 -0.01769737 -0.01769737 -0.01769737]\n",
      " [-0.0079518  -0.0079518  -0.0079518  -0.0079518  -0.0079518  -0.0079518 ]\n",
      " [-0.01423715 -0.01423715 -0.01423715 -0.01423715 -0.01423715 -0.01423715]\n",
      " [-0.01266253 -0.01266253 -0.01266253 -0.01266253 -0.01266253 -0.01266253]\n",
      " [-0.00736754 -0.00736754 -0.00736754 -0.00736754 -0.00736754 -0.00736754]\n",
      " [-0.03662058 -0.03662058 -0.03662058 -0.03662058 -0.03662058 -0.03662058]\n",
      " [-0.03578764 -0.03578764 -0.03578764 -0.03578764 -0.03578764 -0.03578764]\n",
      " [-0.01743995 -0.01743995 -0.01743995 -0.01743995 -0.01743995 -0.01743995]\n",
      " [-0.03845643 -0.03845643 -0.03845643 -0.03845643 -0.03845643 -0.03845643]\n",
      " [-0.00729372 -0.00729372 -0.00729372 -0.00729372 -0.00729372 -0.00729372]\n",
      " [-0.01669429 -0.01669429 -0.01669429 -0.01669429 -0.01669429 -0.01669429]\n",
      " [-0.00798094 -0.00798094 -0.00798094 -0.00798094 -0.00798094 -0.00798094]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]\n",
      " [-0.24841104 -0.24841104 -0.24841104 -0.24841104]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Learned\n",
      "0\n",
      "[0.00010794 0.00010794 0.00010794 0.00010794 0.00010794 0.00010794]\n",
      "0\n",
      "Weights\n",
      "[[0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]\n",
      " [0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]\n",
      " [0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]\n",
      " [0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]\n",
      " [0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]\n",
      " [0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]]\n",
      "Learned\n",
      "1\n",
      "[0.00148773 0.00148773 0.00148773 0.00148773]\n",
      "1\n",
      "Weights\n",
      "[[0.99145951 0.99145951 0.99145951 0.99145951 0.99145951 0.99145951]\n",
      " [0.99145951 0.99145951 0.99145951 0.99145951 0.99145951 0.99145951]\n",
      " [0.99145951 0.99145951 0.99145951 0.99145951 0.99145951 0.99145951]\n",
      " [0.99145951 0.99145951 0.99145951 0.99145951 0.99145951 0.99145951]]\n",
      "Learned\n",
      "2\n",
      "[0.00075 0.00075]\n",
      "2\n",
      "Weights\n",
      "[[0.99437365 0.99437365 0.99437365 0.99437365]\n",
      " [0.99437365 0.99437365 0.99437365 0.99437365]]\n",
      "Epoches changed from initial?\n",
      "[[0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]\n",
      " [0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]\n",
      " [0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]\n",
      " [0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]\n",
      " [0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]\n",
      " [0.99005049 0.99005616 0.99004309 0.99003581 0.99005039 0.99004908\n",
      "  0.99004799 0.99006288]]\n",
      "[0.00010794 0.00010794 0.00010794 0.00010794 0.00010794 0.00010794]\n",
      "Epoches changed from initial?\n",
      "[[0.99145951 0.99145951 0.99145951 0.99145951 0.99145951 0.99145951]\n",
      " [0.99145951 0.99145951 0.99145951 0.99145951 0.99145951 0.99145951]\n",
      " [0.99145951 0.99145951 0.99145951 0.99145951 0.99145951 0.99145951]\n",
      " [0.99145951 0.99145951 0.99145951 0.99145951 0.99145951 0.99145951]]\n",
      "[0.00148773 0.00148773 0.00148773 0.00148773]\n",
      "Epoches changed from initial?\n",
      "[[0.99437365 0.99437365 0.99437365 0.99437365]\n",
      " [0.99437365 0.99437365 0.99437365 0.99437365]]\n",
      "[0.00075 0.00075]\n",
      "Layer Outputs\n",
      "[[0.96223999 0.96223999 0.96223999 0.96223999 0.96223999 0.96223999]\n",
      " [0.99523822 0.99523822 0.99523822 0.99523822 0.99523822 0.99523822]\n",
      " [0.99539248 0.99539248 0.99539248 0.99539248 0.99539248 0.99539248]\n",
      " [0.98124193 0.98124193 0.98124193 0.98124193 0.98124193 0.98124193]\n",
      " [0.99246325 0.99246325 0.99246325 0.99246325 0.99246325 0.99246325]\n",
      " [0.96132436 0.96132436 0.96132436 0.96132436 0.96132436 0.96132436]\n",
      " [0.98697458 0.98697458 0.98697458 0.98697458 0.98697458 0.98697458]\n",
      " [0.92236775 0.92236775 0.92236775 0.92236775 0.92236775 0.92236775]\n",
      " [0.99253935 0.99253935 0.99253935 0.99253935 0.99253935 0.99253935]\n",
      " [0.98169751 0.98169751 0.98169751 0.98169751 0.98169751 0.98169751]\n",
      " [0.99250602 0.99250602 0.99250602 0.99250602 0.99250602 0.99250602]\n",
      " [0.99135513 0.99135513 0.99135513 0.99135513 0.99135513 0.99135513]\n",
      " [0.99121495 0.99121495 0.99121495 0.99121495 0.99121495 0.99121495]\n",
      " [0.95929971 0.95929971 0.95929971 0.95929971 0.95929971 0.95929971]\n",
      " [0.98275344 0.98275344 0.98275344 0.98275344 0.98275344 0.98275344]\n",
      " [0.99186061 0.99186061 0.99186061 0.99186061 0.99186061 0.99186061]\n",
      " [0.99183055 0.99183055 0.99183055 0.99183055 0.99183055 0.99183055]\n",
      " [0.98110767 0.98110767 0.98110767 0.98110767 0.98110767 0.98110767]\n",
      " [0.98196872 0.98196872 0.98196872 0.98196872 0.98196872 0.98196872]\n",
      " [0.98533037 0.98533037 0.98533037 0.98533037 0.98533037 0.98533037]]\n",
      "[[3.23801341 3.23801341 3.23801341 3.23801341 3.23801341 3.23801341]\n",
      " [5.3423603  5.3423603  5.3423603  5.3423603  5.3423603  5.3423603 ]\n",
      " [5.37544765 5.37544765 5.37544765 5.37544765 5.37544765 5.37544765]\n",
      " [3.95719502 3.95719502 3.95719502 3.95719502 3.95719502 3.95719502]\n",
      " [4.8803983  4.8803983  4.8803983  4.8803983  4.8803983  4.8803983 ]\n",
      " [3.2131019  3.2131019  3.2131019  3.2131019  3.2131019  3.2131019 ]\n",
      " [4.32774121 4.32774121 4.32774121 4.32774121 4.32774121 4.32774121]\n",
      " [2.47496109 2.47496109 2.47496109 2.47496109 2.47496109 2.47496109]\n",
      " [4.89062364 4.89062364 4.89062364 4.89062364 4.89062364 4.89062364]\n",
      " [3.98224637 3.98224637 3.98224637 3.98224637 3.98224637 3.98224637]\n",
      " [4.88613371 4.88613371 4.88613371 4.88613371 4.88613371 4.88613371]\n",
      " [4.74210708 4.74210708 4.74210708 4.74210708 4.74210708 4.74210708]\n",
      " [4.7258799  4.7258799  4.7258799  4.7258799  4.7258799  4.7258799 ]\n",
      " [3.1599683  3.1599683  3.1599683  3.1599683  3.1599683  3.1599683 ]\n",
      " [4.04274567 4.04274567 4.04274567 4.04274567 4.04274567 4.04274567]\n",
      " [4.80286754 4.80286754 4.80286754 4.80286754 4.80286754 4.80286754]\n",
      " [4.79915097 4.79915097 4.79915097 4.79915097 4.79915097 4.79915097]\n",
      " [3.94992594 3.94992594 3.94992594 3.94992594 3.94992594 3.94992594]\n",
      " [3.99745133 3.99745133 3.99745133 3.99745133 3.99745133 3.99745133]\n",
      " [4.20719783 4.20719783 4.20719783 4.20719783 4.20719783 4.20719783]]\n",
      "Layer Outputs\n",
      "[[5.72561971 5.72561971 5.72561971 5.72561971]\n",
      " [5.92191813 5.92191813 5.92191813 5.92191813]\n",
      " [5.9228358  5.9228358  5.9228358  5.9228358 ]\n",
      " [5.83865762 5.83865762 5.83865762 5.83865762]\n",
      " [5.90541049 5.90541049 5.90541049 5.90541049]\n",
      " [5.72017282 5.72017282 5.72017282 5.72017282]\n",
      " [5.87275974 5.87275974 5.87275974 5.87275974]\n",
      " [5.48842942 5.48842942 5.48842942 5.48842942]\n",
      " [5.9058632  5.9058632  5.9058632  5.9058632 ]\n",
      " [5.84136777 5.84136777 5.84136777 5.84136777]\n",
      " [5.90566498 5.90566498 5.90566498 5.90566498]\n",
      " [5.8988186  5.8988186  5.8988186  5.8988186 ]\n",
      " [5.89798468 5.89798468 5.89798468 5.89798468]\n",
      " [5.70812867 5.70812867 5.70812867 5.70812867]\n",
      " [5.84764923 5.84764923 5.84764923 5.84764923]\n",
      " [5.90182557 5.90182557 5.90182557 5.90182557]\n",
      " [5.90164675 5.90164675 5.90164675 5.90164675]\n",
      " [5.8378589  5.8378589  5.8378589  5.8378589 ]\n",
      " [5.8429811  5.8429811  5.8429811  5.8429811 ]\n",
      " [5.86297877 5.86297877 5.86297877 5.86297877]]\n",
      "[[5.72561971 5.72561971 5.72561971 5.72561971]\n",
      " [5.92191813 5.92191813 5.92191813 5.92191813]\n",
      " [5.9228358  5.9228358  5.9228358  5.9228358 ]\n",
      " [5.83865762 5.83865762 5.83865762 5.83865762]\n",
      " [5.90541049 5.90541049 5.90541049 5.90541049]\n",
      " [5.72017282 5.72017282 5.72017282 5.72017282]\n",
      " [5.87275974 5.87275974 5.87275974 5.87275974]\n",
      " [5.48842942 5.48842942 5.48842942 5.48842942]\n",
      " [5.9058632  5.9058632  5.9058632  5.9058632 ]\n",
      " [5.84136777 5.84136777 5.84136777 5.84136777]\n",
      " [5.90566498 5.90566498 5.90566498 5.90566498]\n",
      " [5.8988186  5.8988186  5.8988186  5.8988186 ]\n",
      " [5.89798468 5.89798468 5.89798468 5.89798468]\n",
      " [5.70812867 5.70812867 5.70812867 5.70812867]\n",
      " [5.84764923 5.84764923 5.84764923 5.84764923]\n",
      " [5.90182557 5.90182557 5.90182557 5.90182557]\n",
      " [5.90164675 5.90164675 5.90164675 5.90164675]\n",
      " [5.8378589  5.8378589  5.8378589  5.8378589 ]\n",
      " [5.8429811  5.8429811  5.8429811  5.8429811 ]\n",
      " [5.86297877 5.86297877 5.86297877 5.86297877]]\n",
      "Layer Outputs\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[[22.77437139 22.77437139]\n",
      " [23.55514729 23.55514729]\n",
      " [23.55879732 23.55879732]\n",
      " [23.22397903 23.22397903]\n",
      " [23.48948823 23.48948823]\n",
      " [22.75270639 22.75270639]\n",
      " [23.35962003 23.35962003]\n",
      " [21.83094829 21.83094829]\n",
      " [23.49128887 23.49128887]\n",
      " [23.23475867 23.23475867]\n",
      " [23.49050044 23.49050044]\n",
      " [23.46326902 23.46326902]\n",
      " [23.45995211 23.45995211]\n",
      " [22.70480084 22.70480084]\n",
      " [23.25974312 23.25974312]\n",
      " [23.47522922 23.47522922]\n",
      " [23.47451799 23.47451799]\n",
      " [23.22080216 23.22080216]\n",
      " [23.24117566 23.24117566]\n",
      " [23.32071627 23.32071627]]\n",
      "Delta Last\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.03582119 -0.03582119 -0.03582119 -0.03582119 -0.03582119 -0.03582119]\n",
      " [-0.0046722  -0.0046722  -0.0046722  -0.0046722  -0.0046722  -0.0046722 ]\n",
      " [-0.00452154 -0.00452154 -0.00452154 -0.00452154 -0.00452154 -0.00452154]\n",
      " [-0.01814633 -0.01814633 -0.01814633 -0.01814633 -0.01814633 -0.01814633]\n",
      " [-0.00737434 -0.00737434 -0.00737434 -0.00737434 -0.00737434 -0.00737434]\n",
      " [-0.0366549  -0.0366549  -0.0366549  -0.0366549  -0.0366549  -0.0366549 ]\n",
      " [-0.01267425 -0.01267425 -0.01267425 -0.01267425 -0.01267425 -0.01267425]\n",
      " [-0.0705945  -0.0705945  -0.0705945  -0.0705945  -0.0705945  -0.0705945 ]\n",
      " [-0.00730044 -0.00730044 -0.00730044 -0.00730044 -0.00730044 -0.00730044]\n",
      " [-0.01771383 -0.01771383 -0.01771383 -0.01771383 -0.01771383 -0.01771383]\n",
      " [-0.0073328  -0.0073328  -0.0073328  -0.0073328  -0.0073328  -0.0073328 ]\n",
      " [-0.00844913 -0.00844913 -0.00844913 -0.00844913 -0.00844913 -0.00844913]\n",
      " [-0.00858493 -0.00858493 -0.00858493 -0.00858493 -0.00858493 -0.00858493]\n",
      " [-0.03849253 -0.03849253 -0.03849253 -0.03849253 -0.03849253 -0.03849253]\n",
      " [-0.01670981 -0.01670981 -0.01670981 -0.01670981 -0.01670981 -0.01670981]\n",
      " [-0.00795916 -0.00795916 -0.00795916 -0.00795916 -0.00795916 -0.00795916]\n",
      " [-0.00798831 -0.00798831 -0.00798831 -0.00798831 -0.00798831 -0.00798831]\n",
      " [-0.01827372 -0.01827372 -0.01827372 -0.01827372 -0.01827372 -0.01827372]\n",
      " [-0.01745617 -0.01745617 -0.01745617 -0.01745617 -0.01745617 -0.01745617]\n",
      " [-0.01425035 -0.01425035 -0.01425035 -0.01425035 -0.01425035 -0.01425035]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]\n",
      " [-0.24859341 -0.24859341 -0.24859341 -0.24859341]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Learned\n",
      "0\n",
      "[0.00012599 0.00012599 0.00012599 0.00012599 0.00012599 0.00012599]\n",
      "0\n",
      "Weights\n",
      "[[0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]\n",
      " [0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]\n",
      " [0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]\n",
      " [0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]\n",
      " [0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]\n",
      " [0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]]\n",
      "Learned\n",
      "1\n",
      "[0.00173633 0.00173633 0.00173633 0.00173633]\n",
      "1\n",
      "Weights\n",
      "[[0.99170339 0.99170339 0.99170339 0.99170339 0.99170339 0.99170339]\n",
      " [0.99170339 0.99170339 0.99170339 0.99170339 0.99170339 0.99170339]\n",
      " [0.99170339 0.99170339 0.99170339 0.99170339 0.99170339 0.99170339]\n",
      " [0.99170339 0.99170339 0.99170339 0.99170339 0.99170339 0.99170339]]\n",
      "Learned\n",
      "2\n",
      "[0.000875 0.000875]\n",
      "2\n",
      "Weights\n",
      "[[0.99510332 0.99510332 0.99510332 0.99510332]\n",
      " [0.99510332 0.99510332 0.99510332 0.99510332]]\n",
      "Epoches changed from initial?\n",
      "[[0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]\n",
      " [0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]\n",
      " [0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]\n",
      " [0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]\n",
      " [0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]\n",
      " [0.99005893 0.99006555 0.99005029 0.9900418  0.99005881 0.99005729\n",
      "  0.99005602 0.99007339]]\n",
      "[0.00012599 0.00012599 0.00012599 0.00012599 0.00012599 0.00012599]\n",
      "Epoches changed from initial?\n",
      "[[0.99170339 0.99170339 0.99170339 0.99170339 0.99170339 0.99170339]\n",
      " [0.99170339 0.99170339 0.99170339 0.99170339 0.99170339 0.99170339]\n",
      " [0.99170339 0.99170339 0.99170339 0.99170339 0.99170339 0.99170339]\n",
      " [0.99170339 0.99170339 0.99170339 0.99170339 0.99170339 0.99170339]]\n",
      "[0.00173633 0.00173633 0.00173633 0.00173633]\n",
      "Epoches changed from initial?\n",
      "[[0.99510332 0.99510332 0.99510332 0.99510332]\n",
      " [0.99510332 0.99510332 0.99510332 0.99510332]]\n",
      "[0.000875 0.000875]\n",
      "Layer Outputs\n",
      "[[0.99246368 0.99246368 0.99246368 0.99246368 0.99246368 0.99246368]\n",
      " [0.96132609 0.96132609 0.96132609 0.96132609 0.96132609 0.96132609]\n",
      " [0.99186106 0.99186106 0.99186106 0.99186106 0.99186106 0.99186106]\n",
      " [0.98275432 0.98275432 0.98275432 0.98275432 0.98275432 0.98275432]\n",
      " [0.99121545 0.99121545 0.99121545 0.99121545 0.99121545 0.99121545]\n",
      " [0.98697529 0.98697529 0.98697529 0.98697529 0.98697529 0.98697529]\n",
      " [0.98196964 0.98196964 0.98196964 0.98196964 0.98196964 0.98196964]\n",
      " [0.96224167 0.96224167 0.96224167 0.96224167 0.96224167 0.96224167]\n",
      " [0.95930148 0.95930148 0.95930148 0.95930148 0.95930148 0.95930148]\n",
      " [0.99253979 0.99253979 0.99253979 0.99253979 0.99253979 0.99253979]\n",
      " [0.99539277 0.99539277 0.99539277 0.99539277 0.99539277 0.99539277]\n",
      " [0.98124292 0.98124292 0.98124292 0.98124292 0.98124292 0.98124292]\n",
      " [0.92237049 0.92237049 0.92237049 0.92237049 0.92237049 0.92237049]\n",
      " [0.98110865 0.98110865 0.98110865 0.98110865 0.98110865 0.98110865]\n",
      " [0.99135565 0.99135565 0.99135565 0.99135565 0.99135565 0.99135565]\n",
      " [0.99523851 0.99523851 0.99523851 0.99523851 0.99523851 0.99523851]\n",
      " [0.98169845 0.98169845 0.98169845 0.98169845 0.98169845 0.98169845]\n",
      " [0.99183103 0.99183103 0.99183103 0.99183103 0.99183103 0.99183103]\n",
      " [0.99250647 0.99250647 0.99250647 0.99250647 0.99250647 0.99250647]\n",
      " [0.98533116 0.98533116 0.98533116 0.98533116 0.98533116 0.98533116]]\n",
      "[[4.8804559  4.8804559  4.8804559  4.8804559  4.8804559  4.8804559 ]\n",
      " [3.21314838 3.21314838 3.21314838 3.21314838 3.21314838 3.21314838]\n",
      " [4.80292351 4.80292351 4.80292351 4.80292351 4.80292351 4.80292351]\n",
      " [4.04279757 4.04279757 4.04279757 4.04279757 4.04279757 4.04279757]\n",
      " [4.72593783 4.72593783 4.72593783 4.72593783 4.72593783 4.72593783]\n",
      " [4.32779658 4.32779658 4.32779658 4.32779658 4.32779658 4.32779658]\n",
      " [3.9975036  3.9975036  3.9975036  3.9975036  3.9975036  3.9975036 ]\n",
      " [3.23805959 3.23805959 3.23805959 3.23805959 3.23805959 3.23805959]\n",
      " [3.16001355 3.16001355 3.16001355 3.16001355 3.16001355 3.16001355]\n",
      " [4.89068363 4.89068363 4.89068363 4.89068363 4.89068363 4.89068363]\n",
      " [5.37551076 5.37551076 5.37551076 5.37551076 5.37551076 5.37551076]\n",
      " [3.95724872 3.95724872 3.95724872 3.95724872 3.95724872 3.95724872]\n",
      " [2.47499935 2.47499935 2.47499935 2.47499935 2.47499935 2.47499935]\n",
      " [3.94997909 3.94997909 3.94997909 3.94997909 3.94997909 3.94997909]\n",
      " [4.74216735 4.74216735 4.74216735 4.74216735 4.74216735 4.74216735]\n",
      " [5.34242243 5.34242243 5.34242243 5.34242243 5.34242243 5.34242243]\n",
      " [3.98229867 3.98229867 3.98229867 3.98229867 3.98229867 3.98229867]\n",
      " [4.79920947 4.79920947 4.79920947 4.79920947 4.79920947 4.79920947]\n",
      " [4.88619321 4.88619321 4.88619321 4.88619321 4.88619321 4.88619321]\n",
      " [4.20725225 4.20725225 4.20725225 4.20725225 4.20725225 4.20725225]]\n",
      "Layer Outputs\n",
      "[[5.90711389 5.90711389 5.90711389 5.90711389]\n",
      " [5.72183838 5.72183838 5.72183838 5.72183838]\n",
      " [5.90352821 5.90352821 5.90352821 5.90352821]\n",
      " [5.84934109 5.84934109 5.84934109 5.84934109]\n",
      " [5.89968669 5.89968669 5.89968669 5.89968669]\n",
      " [5.87445678 5.87445678 5.87445678 5.87445678]\n",
      " [5.84467209 5.84467209 5.84467209 5.84467209]\n",
      " [5.72728631 5.72728631 5.72728631 5.72728631]\n",
      " [5.70979149 5.70979149 5.70979149 5.70979149]\n",
      " [5.90756679 5.90756679 5.90756679 5.90756679]\n",
      " [5.92454265 5.92454265 5.92454265 5.92454265]\n",
      " [5.84034792 5.84034792 5.84034792 5.84034792]\n",
      " [5.490044   5.490044   5.490044   5.490044  ]\n",
      " [5.83954899 5.83954899 5.83954899 5.83954899]\n",
      " [5.90052089 5.90052089 5.90052089 5.90052089]\n",
      " [5.92362478 5.92362478 5.92362478 5.92362478]\n",
      " [5.84305845 5.84305845 5.84305845 5.84305845]\n",
      " [5.90334949 5.90334949 5.90334949 5.90334949]\n",
      " [5.90736851 5.90736851 5.90736851 5.90736851]\n",
      " [5.86467385 5.86467385 5.86467385 5.86467385]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.90711389 5.90711389 5.90711389 5.90711389]\n",
      " [5.72183838 5.72183838 5.72183838 5.72183838]\n",
      " [5.90352821 5.90352821 5.90352821 5.90352821]\n",
      " [5.84934109 5.84934109 5.84934109 5.84934109]\n",
      " [5.89968669 5.89968669 5.89968669 5.89968669]\n",
      " [5.87445678 5.87445678 5.87445678 5.87445678]\n",
      " [5.84467209 5.84467209 5.84467209 5.84467209]\n",
      " [5.72728631 5.72728631 5.72728631 5.72728631]\n",
      " [5.70979149 5.70979149 5.70979149 5.70979149]\n",
      " [5.90756679 5.90756679 5.90756679 5.90756679]\n",
      " [5.92454265 5.92454265 5.92454265 5.92454265]\n",
      " [5.84034792 5.84034792 5.84034792 5.84034792]\n",
      " [5.490044   5.490044   5.490044   5.490044  ]\n",
      " [5.83954899 5.83954899 5.83954899 5.83954899]\n",
      " [5.90052089 5.90052089 5.90052089 5.90052089]\n",
      " [5.92362478 5.92362478 5.92362478 5.92362478]\n",
      " [5.84305845 5.84305845 5.84305845 5.84305845]\n",
      " [5.90334949 5.90334949 5.90334949 5.90334949]\n",
      " [5.90736851 5.90736851 5.90736851 5.90736851]\n",
      " [5.86467385 5.86467385 5.86467385 5.86467385]]\n",
      "Layer Outputs\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[[23.51362968 23.51362968]\n",
      " [22.77615655 22.77615655]\n",
      " [23.4993572  23.4993572 ]\n",
      " [23.28367006 23.28367006]\n",
      " [23.48406636 23.48406636]\n",
      " [23.38364087 23.38364087]\n",
      " [23.26508549 23.26508549]\n",
      " [22.79784158 22.79784158]\n",
      " [22.72820497 22.72820497]\n",
      " [23.5154324  23.5154324 ]\n",
      " [23.58300334 23.58300334]\n",
      " [23.24787349 23.24787349]\n",
      " [21.85351912 21.85351912]\n",
      " [23.24469344 23.24469344]\n",
      " [23.4873868  23.4873868 ]\n",
      " [23.57934985 23.57934985]\n",
      " [23.25866255 23.25866255]\n",
      " [23.49864579 23.49864579]\n",
      " [23.51464316 23.51464316]\n",
      " [23.34470076 23.34470076]]\n",
      "Delta Last\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.00738115 -0.00738115 -0.00738115 -0.00738115 -0.00738115 -0.00738115]\n",
      " [-0.03668925 -0.03668925 -0.03668925 -0.03668925 -0.03668925 -0.03668925]\n",
      " [-0.00796652 -0.00796652 -0.00796652 -0.00796652 -0.00796652 -0.00796652]\n",
      " [-0.01672535 -0.01672535 -0.01672535 -0.01672535 -0.01672535 -0.01672535]\n",
      " [-0.00859285 -0.00859285 -0.00859285 -0.00859285 -0.00859285 -0.00859285]\n",
      " [-0.01268599 -0.01268599 -0.01268599 -0.01268599 -0.01268599 -0.01268599]\n",
      " [-0.01747239 -0.01747239 -0.01747239 -0.01747239 -0.01747239 -0.01747239]\n",
      " [-0.03585477 -0.03585477 -0.03585477 -0.03585477 -0.03585477 -0.03585477]\n",
      " [-0.03852865 -0.03852865 -0.03852865 -0.03852865 -0.03852865 -0.03852865]\n",
      " [-0.00730717 -0.00730717 -0.00730717 -0.00730717 -0.00730717 -0.00730717]\n",
      " [-0.00452568 -0.00452568 -0.00452568 -0.00452568 -0.00452568 -0.00452568]\n",
      " [-0.01816317 -0.01816317 -0.01816317 -0.01816317 -0.01816317 -0.01816317]\n",
      " [-0.0706614  -0.0706614  -0.0706614  -0.0706614  -0.0706614  -0.0706614 ]\n",
      " [-0.01829069 -0.01829069 -0.01829069 -0.01829069 -0.01829069 -0.01829069]\n",
      " [-0.00845691 -0.00845691 -0.00845691 -0.00845691 -0.00845691 -0.00845691]\n",
      " [-0.00467649 -0.00467649 -0.00467649 -0.00467649 -0.00467649 -0.00467649]\n",
      " [-0.01773029 -0.01773029 -0.01773029 -0.01773029 -0.01773029 -0.01773029]\n",
      " [-0.00799568 -0.00799568 -0.00799568 -0.00799568 -0.00799568 -0.00799568]\n",
      " [-0.00733956 -0.00733956 -0.00733956 -0.00733956 -0.00733956 -0.00733956]\n",
      " [-0.01426356 -0.01426356 -0.01426356 -0.01426356 -0.01426356 -0.01426356]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]\n",
      " [-0.24877583 -0.24877583 -0.24877583 -0.24877583]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Learned\n",
      "0\n",
      "[0.00014405 0.00014405 0.00014405 0.00014405 0.00014405 0.00014405]\n",
      "0\n",
      "Weights\n",
      "[[0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]\n",
      " [0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]\n",
      " [0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]\n",
      " [0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]\n",
      " [0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]\n",
      " [0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]]\n",
      "Learned\n",
      "1\n",
      "[0.0019851 0.0019851 0.0019851 0.0019851]\n",
      "1\n",
      "Weights\n",
      "[[0.99194745 0.99194745 0.99194745 0.99194745 0.99194745 0.99194745]\n",
      " [0.99194745 0.99194745 0.99194745 0.99194745 0.99194745 0.99194745]\n",
      " [0.99194745 0.99194745 0.99194745 0.99194745 0.99194745 0.99194745]\n",
      " [0.99194745 0.99194745 0.99194745 0.99194745 0.99194745 0.99194745]]\n",
      "Learned\n",
      "2\n",
      "[0.001 0.001]\n",
      "2\n",
      "Weights\n",
      "[[0.99583321 0.99583321 0.99583321 0.99583321]\n",
      " [0.99583321 0.99583321 0.99583321 0.99583321]]\n",
      "Epoches changed from initial?\n",
      "[[0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]\n",
      " [0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]\n",
      " [0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]\n",
      " [0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]\n",
      " [0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]\n",
      " [0.99006738 0.99007495 0.99005751 0.99004779 0.99006724 0.9900655\n",
      "  0.99006405 0.99008391]]\n",
      "[0.00014405 0.00014405 0.00014405 0.00014405 0.00014405 0.00014405]\n",
      "Epoches changed from initial?\n",
      "[[0.99194745 0.99194745 0.99194745 0.99194745 0.99194745 0.99194745]\n",
      " [0.99194745 0.99194745 0.99194745 0.99194745 0.99194745 0.99194745]\n",
      " [0.99194745 0.99194745 0.99194745 0.99194745 0.99194745 0.99194745]\n",
      " [0.99194745 0.99194745 0.99194745 0.99194745 0.99194745 0.99194745]]\n",
      "[0.0019851 0.0019851 0.0019851 0.0019851]\n",
      "Epoches changed from initial?\n",
      "[[0.99583321 0.99583321 0.99583321 0.99583321]\n",
      " [0.99583321 0.99583321 0.99583321 0.99583321]]\n",
      "[0.001 0.001]\n",
      "Layer Outputs\n",
      "[[0.95930324 0.95930324 0.95930324 0.95930324 0.95930324 0.95930324]\n",
      " [0.986976   0.986976   0.986976   0.986976   0.986976   0.986976  ]\n",
      " [0.98169939 0.98169939 0.98169939 0.98169939 0.98169939 0.98169939]\n",
      " [0.9918315  0.9918315  0.9918315  0.9918315  0.9918315  0.9918315 ]\n",
      " [0.99254024 0.99254024 0.99254024 0.99254024 0.99254024 0.99254024]\n",
      " [0.99523881 0.99523881 0.99523881 0.99523881 0.99523881 0.99523881]\n",
      " [0.92237323 0.92237323 0.92237323 0.92237323 0.92237323 0.92237323]\n",
      " [0.99135617 0.99135617 0.99135617 0.99135617 0.99135617 0.99135617]\n",
      " [0.98110964 0.98110964 0.98110964 0.98110964 0.98110964 0.98110964]\n",
      " [0.96224335 0.96224335 0.96224335 0.96224335 0.96224335 0.96224335]\n",
      " [0.99186152 0.99186152 0.99186152 0.99186152 0.99186152 0.99186152]\n",
      " [0.99121596 0.99121596 0.99121596 0.99121596 0.99121596 0.99121596]\n",
      " [0.98197057 0.98197057 0.98197057 0.98197057 0.98197057 0.98197057]\n",
      " [0.9827552  0.9827552  0.9827552  0.9827552  0.9827552  0.9827552 ]\n",
      " [0.98124391 0.98124391 0.98124391 0.98124391 0.98124391 0.98124391]\n",
      " [0.96132782 0.96132782 0.96132782 0.96132782 0.96132782 0.96132782]\n",
      " [0.99539306 0.99539306 0.99539306 0.99539306 0.99539306 0.99539306]\n",
      " [0.98533195 0.98533195 0.98533195 0.98533195 0.98533195 0.98533195]\n",
      " [0.99246411 0.99246411 0.99246411 0.99246411 0.99246411 0.99246411]\n",
      " [0.99250691 0.99250691 0.99250691 0.99250691 0.99250691 0.99250691]]\n",
      "[[3.16005884 3.16005884 3.16005884 3.16005884 3.16005884 3.16005884]\n",
      " [4.32785201 4.32785201 4.32785201 4.32785201 4.32785201 4.32785201]\n",
      " [3.98235102 3.98235102 3.98235102 3.98235102 3.98235102 3.98235102]\n",
      " [4.79926801 4.79926801 4.79926801 4.79926801 4.79926801 4.79926801]\n",
      " [4.89074367 4.89074367 4.89074367 4.89074367 4.89074367 4.89074367]\n",
      " [5.34248461 5.34248461 5.34248461 5.34248461 5.34248461 5.34248461]\n",
      " [2.47503765 2.47503765 2.47503765 2.47503765 2.47503765 2.47503765]\n",
      " [4.74222768 4.74222768 4.74222768 4.74222768 4.74222768 4.74222768]\n",
      " [3.9500323  3.9500323  3.9500323  3.9500323  3.9500323  3.9500323 ]\n",
      " [3.23810582 3.23810582 3.23810582 3.23810582 3.23810582 3.23810582]\n",
      " [4.80297953 4.80297953 4.80297953 4.80297953 4.80297953 4.80297953]\n",
      " [4.72599581 4.72599581 4.72599581 4.72599581 4.72599581 4.72599581]\n",
      " [3.99755592 3.99755592 3.99755592 3.99755592 3.99755592 3.99755592]\n",
      " [4.04284952 4.04284952 4.04284952 4.04284952 4.04284952 4.04284952]\n",
      " [3.95730247 3.95730247 3.95730247 3.95730247 3.95730247 3.95730247]\n",
      " [3.2131949  3.2131949  3.2131949  3.2131949  3.2131949  3.2131949 ]\n",
      " [5.37557393 5.37557393 5.37557393 5.37557393 5.37557393 5.37557393]\n",
      " [4.20730673 4.20730673 4.20730673 4.20730673 4.20730673 4.20730673]\n",
      " [4.88051355 4.88051355 4.88051355 4.88051355 4.88051355 4.88051355]\n",
      " [4.88625276 4.88625276 4.88625276 4.88625276 4.88625276 4.88625276]]\n",
      "Layer Outputs\n",
      "[[5.71145554 5.71145554 5.71145554 5.71145554]\n",
      " [5.87615507 5.87615507 5.87615507 5.87615507]\n",
      " [5.84475037 5.84475037 5.84475037 5.84475037]\n",
      " [5.90505347 5.90505347 5.90505347 5.90505347]\n",
      " [5.90927164 5.90927164 5.90927164 5.90927164]\n",
      " [5.92533269 5.92533269 5.92533269 5.92533269]\n",
      " [5.49165977 5.49165977 5.49165977 5.49165977]\n",
      " [5.90222443 5.90222443 5.90222443 5.90222443]\n",
      " [5.84124032 5.84124032 5.84124032 5.84124032]\n",
      " [5.72895414 5.72895414 5.72895414 5.72895414]\n",
      " [5.90523211 5.90523211 5.90523211 5.90523211]\n",
      " [5.90138996 5.90138996 5.90138996 5.90138996]\n",
      " [5.84636432 5.84636432 5.84636432 5.84636432]\n",
      " [5.8510342  5.8510342  5.8510342  5.8510342 ]\n",
      " [5.84203946 5.84203946 5.84203946 5.84203946]\n",
      " [5.72350516 5.72350516 5.72350516 5.72350516]\n",
      " [5.92625075 5.92625075 5.92625075 5.92625075]\n",
      " [5.86637018 5.86637018 5.86637018 5.86637018]\n",
      " [5.90881855 5.90881855 5.90881855 5.90881855]\n",
      " [5.9090733  5.9090733  5.9090733  5.9090733 ]]\n",
      "[[5.71145554 5.71145554 5.71145554 5.71145554]\n",
      " [5.87615507 5.87615507 5.87615507 5.87615507]\n",
      " [5.84475037 5.84475037 5.84475037 5.84475037]\n",
      " [5.90505347 5.90505347 5.90505347 5.90505347]\n",
      " [5.90927164 5.90927164 5.90927164 5.90927164]\n",
      " [5.92533269 5.92533269 5.92533269 5.92533269]\n",
      " [5.49165977 5.49165977 5.49165977 5.49165977]\n",
      " [5.90222443 5.90222443 5.90222443 5.90222443]\n",
      " [5.84124032 5.84124032 5.84124032 5.84124032]\n",
      " [5.72895414 5.72895414 5.72895414 5.72895414]\n",
      " [5.90523211 5.90523211 5.90523211 5.90523211]\n",
      " [5.90138996 5.90138996 5.90138996 5.90138996]\n",
      " [5.84636432 5.84636432 5.84636432 5.84636432]\n",
      " [5.8510342  5.8510342  5.8510342  5.8510342 ]\n",
      " [5.84203946 5.84203946 5.84203946 5.84203946]\n",
      " [5.72350516 5.72350516 5.72350516 5.72350516]\n",
      " [5.92625075 5.92625075 5.92625075 5.92625075]\n",
      " [5.86637018 5.86637018 5.86637018 5.86637018]\n",
      " [5.90881855 5.90881855 5.90881855 5.90881855]\n",
      " [5.9090733  5.9090733  5.9090733  5.9090733 ]]\n",
      "Layer Outputs\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[[22.75162851 22.75162851]\n",
      " [23.40768155 23.40768155]\n",
      " [23.28258619 23.28258619]\n",
      " [23.5227935  23.5227935 ]\n",
      " [23.53959586 23.53959586]\n",
      " [23.60357238 23.60357238]\n",
      " [21.87610877 21.87610877]\n",
      " [23.5115245  23.5115245 ]\n",
      " [23.26860448 23.26860448]\n",
      " [22.82133125 22.82133125]\n",
      " [23.52350509 23.52350509]\n",
      " [23.50820051 23.50820051]\n",
      " [23.28901509 23.28901509]\n",
      " [23.30761678 23.30761678]\n",
      " [23.27178772 23.27178772]\n",
      " [22.79962616 22.79962616]\n",
      " [23.60722933 23.60722933]\n",
      " [23.36870507 23.36870507]\n",
      " [23.53779105 23.53779105]\n",
      " [23.53880581 23.53880581]]\n",
      "Delta Last\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.03856479 -0.03856479 -0.03856479 -0.03856479 -0.03856479 -0.03856479]\n",
      " [-0.01269773 -0.01269773 -0.01269773 -0.01269773 -0.01269773 -0.01269773]\n",
      " [-0.01774677 -0.01774677 -0.01774677 -0.01774677 -0.01774677 -0.01774677]\n",
      " [-0.00800305 -0.00800305 -0.00800305 -0.00800305 -0.00800305 -0.00800305]\n",
      " [-0.00731389 -0.00731389 -0.00731389 -0.00731389 -0.00731389 -0.00731389]\n",
      " [-0.00468078 -0.00468078 -0.00468078 -0.00468078 -0.00468078 -0.00468078]\n",
      " [-0.07072834 -0.07072834 -0.07072834 -0.07072834 -0.07072834 -0.07072834]\n",
      " [-0.0084647  -0.0084647  -0.0084647  -0.0084647  -0.0084647  -0.0084647 ]\n",
      " [-0.01830767 -0.01830767 -0.01830767 -0.01830767 -0.01830767 -0.01830767]\n",
      " [-0.03588836 -0.03588836 -0.03588836 -0.03588836 -0.03588836 -0.03588836]\n",
      " [-0.00797388 -0.00797388 -0.00797388 -0.00797388 -0.00797388 -0.00797388]\n",
      " [-0.00860078 -0.00860078 -0.00860078 -0.00860078 -0.00860078 -0.00860078]\n",
      " [-0.01748863 -0.01748863 -0.01748863 -0.01748863 -0.01748863 -0.01748863]\n",
      " [-0.0167409  -0.0167409  -0.0167409  -0.0167409  -0.0167409  -0.0167409 ]\n",
      " [-0.01818003 -0.01818003 -0.01818003 -0.01818003 -0.01818003 -0.01818003]\n",
      " [-0.03672362 -0.03672362 -0.03672362 -0.03672362 -0.03672362 -0.03672362]\n",
      " [-0.00452984 -0.00452984 -0.00452984 -0.00452984 -0.00452984 -0.00452984]\n",
      " [-0.01427678 -0.01427678 -0.01427678 -0.01427678 -0.01427678 -0.01427678]\n",
      " [-0.00738796 -0.00738796 -0.00738796 -0.00738796 -0.00738796 -0.00738796]\n",
      " [-0.00734632 -0.00734632 -0.00734632 -0.00734632 -0.00734632 -0.00734632]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]\n",
      " [-0.2489583 -0.2489583 -0.2489583 -0.2489583]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Learned\n",
      "0\n",
      "[0.00016213 0.00016213 0.00016213 0.00016213 0.00016213 0.00016213]\n",
      "0\n",
      "Weights\n",
      "[[0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]\n",
      " [0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]\n",
      " [0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]\n",
      " [0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]\n",
      " [0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]\n",
      " [0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]]\n",
      "Learned\n",
      "1\n",
      "[0.00223406 0.00223406 0.00223406 0.00223406]\n",
      "1\n",
      "Weights\n",
      "[[0.99219169 0.99219169 0.99219169 0.99219169 0.99219169 0.99219169]\n",
      " [0.99219169 0.99219169 0.99219169 0.99219169 0.99219169 0.99219169]\n",
      " [0.99219169 0.99219169 0.99219169 0.99219169 0.99219169 0.99219169]\n",
      " [0.99219169 0.99219169 0.99219169 0.99219169 0.99219169 0.99219169]]\n",
      "Learned\n",
      "2\n",
      "[0.001125 0.001125]\n",
      "2\n",
      "Weights\n",
      "[[0.99656331 0.99656331 0.99656331 0.99656331]\n",
      " [0.99656331 0.99656331 0.99656331 0.99656331]]\n",
      "Epoches changed from initial?\n",
      "[[0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]\n",
      " [0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]\n",
      " [0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]\n",
      " [0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]\n",
      " [0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]\n",
      " [0.99007583 0.99008436 0.99006472 0.99005379 0.99007569 0.99007372\n",
      "  0.99007209 0.99009444]]\n",
      "[0.00016213 0.00016213 0.00016213 0.00016213 0.00016213 0.00016213]\n",
      "Epoches changed from initial?\n",
      "[[0.99219169 0.99219169 0.99219169 0.99219169 0.99219169 0.99219169]\n",
      " [0.99219169 0.99219169 0.99219169 0.99219169 0.99219169 0.99219169]\n",
      " [0.99219169 0.99219169 0.99219169 0.99219169 0.99219169 0.99219169]\n",
      " [0.99219169 0.99219169 0.99219169 0.99219169 0.99219169 0.99219169]]\n",
      "[0.00223406 0.00223406 0.00223406 0.00223406]\n",
      "Epoches changed from initial?\n",
      "[[0.99656331 0.99656331 0.99656331 0.99656331]\n",
      " [0.99656331 0.99656331 0.99656331 0.99656331]]\n",
      "[0.001125 0.001125]\n",
      "Layer Outputs\n",
      "[[0.99135668 0.99135668 0.99135668 0.99135668 0.99135668 0.99135668]\n",
      " [0.92237598 0.92237598 0.92237598 0.92237598 0.92237598 0.92237598]\n",
      " [0.99186197 0.99186197 0.99186197 0.99186197 0.99186197 0.99186197]\n",
      " [0.96132955 0.96132955 0.96132955 0.96132955 0.96132955 0.96132955]\n",
      " [0.99250735 0.99250735 0.99250735 0.99250735 0.99250735 0.99250735]\n",
      " [0.98275608 0.98275608 0.98275608 0.98275608 0.98275608 0.98275608]\n",
      " [0.95930501 0.95930501 0.95930501 0.95930501 0.95930501 0.95930501]\n",
      " [0.98170034 0.98170034 0.98170034 0.98170034 0.98170034 0.98170034]\n",
      " [0.98111062 0.98111062 0.98111062 0.98111062 0.98111062 0.98111062]\n",
      " [0.99183198 0.99183198 0.99183198 0.99183198 0.99183198 0.99183198]\n",
      " [0.99121646 0.99121646 0.99121646 0.99121646 0.99121646 0.99121646]\n",
      " [0.99246454 0.99246454 0.99246454 0.99246454 0.99246454 0.99246454]\n",
      " [0.98533274 0.98533274 0.98533274 0.98533274 0.98533274 0.98533274]\n",
      " [0.9812449  0.9812449  0.9812449  0.9812449  0.9812449  0.9812449 ]\n",
      " [0.96224503 0.96224503 0.96224503 0.96224503 0.96224503 0.96224503]\n",
      " [0.99254068 0.99254068 0.99254068 0.99254068 0.99254068 0.99254068]\n",
      " [0.9952391  0.9952391  0.9952391  0.9952391  0.9952391  0.9952391 ]\n",
      " [0.99539335 0.99539335 0.99539335 0.99539335 0.99539335 0.99539335]\n",
      " [0.9819715  0.9819715  0.9819715  0.9819715  0.9819715  0.9819715 ]\n",
      " [0.98697671 0.98697671 0.98697671 0.98697671 0.98697671 0.98697671]]\n",
      "[[4.74228807 4.74228807 4.74228807 4.74228807 4.74228807 4.74228807]\n",
      " [2.47507599 2.47507599 2.47507599 2.47507599 2.47507599 2.47507599]\n",
      " [4.8030356  4.8030356  4.8030356  4.8030356  4.8030356  4.8030356 ]\n",
      " [3.21324147 3.21324147 3.21324147 3.21324147 3.21324147 3.21324147]\n",
      " [4.88631237 4.88631237 4.88631237 4.88631237 4.88631237 4.88631237]\n",
      " [4.04290151 4.04290151 4.04290151 4.04290151 4.04290151 4.04290151]\n",
      " [3.16010418 3.16010418 3.16010418 3.16010418 3.16010418 3.16010418]\n",
      " [3.98240342 3.98240342 3.98240342 3.98240342 3.98240342 3.98240342]\n",
      " [3.95008556 3.95008556 3.95008556 3.95008556 3.95008556 3.95008556]\n",
      " [4.79932662 4.79932662 4.79932662 4.79932662 4.79932662 4.79932662]\n",
      " [4.72605384 4.72605384 4.72605384 4.72605384 4.72605384 4.72605384]\n",
      " [4.88057125 4.88057125 4.88057125 4.88057125 4.88057125 4.88057125]\n",
      " [4.20736125 4.20736125 4.20736125 4.20736125 4.20736125 4.20736125]\n",
      " [3.95735627 3.95735627 3.95735627 3.95735627 3.95735627 3.95735627]\n",
      " [3.23815209 3.23815209 3.23815209 3.23815209 3.23815209 3.23815209]\n",
      " [4.89080376 4.89080376 4.89080376 4.89080376 4.89080376 4.89080376]\n",
      " [5.34254685 5.34254685 5.34254685 5.34254685 5.34254685 5.34254685]\n",
      " [5.37563716 5.37563716 5.37563716 5.37563716 5.37563716 5.37563716]\n",
      " [3.99760829 3.99760829 3.99760829 3.99760829 3.99760829 3.99760829]\n",
      " [4.32790748 4.32790748 4.32790748 4.32790748 4.32790748 4.32790748]]\n",
      "Layer Outputs\n",
      "[[5.90392923 5.90392923 5.90392923 5.90392923]\n",
      " [5.49327673 5.49327673 5.49327673 5.49327673]\n",
      " [5.90693726 5.90693726 5.90693726 5.90693726]\n",
      " [5.72517318 5.72517318 5.72517318 5.72517318]\n",
      " [5.91077934 5.91077934 5.91077934 5.91077934]\n",
      " [5.85272856 5.85272856 5.85272856 5.85272856]\n",
      " [5.71312082 5.71312082 5.71312082 5.71312082]\n",
      " [5.84644354 5.84644354 5.84644354 5.84644354]\n",
      " [5.8429329  5.8429329  5.8429329  5.8429329 ]\n",
      " [5.90675871 5.90675871 5.90675871 5.90675871]\n",
      " [5.90309448 5.90309448 5.90309448 5.90309448]\n",
      " [5.91052446 5.91052446 5.91052446 5.91052446]\n",
      " [5.86806776 5.86806776 5.86806776 5.86806776]\n",
      " [5.84373225 5.84373225 5.84373225 5.84373225]\n",
      " [5.7306232  5.7306232  5.7306232  5.7306232 ]\n",
      " [5.91097774 5.91097774 5.91097774 5.91097774]\n",
      " [5.92704185 5.92704185 5.92704185 5.92704185]\n",
      " [5.92796011 5.92796011 5.92796011 5.92796011]\n",
      " [5.8480578  5.8480578  5.8480578  5.8480578 ]\n",
      " [5.87785461 5.87785461 5.87785461 5.87785461]]\n",
      "[[5.90392923 5.90392923 5.90392923 5.90392923]\n",
      " [5.49327673 5.49327673 5.49327673 5.49327673]\n",
      " [5.90693726 5.90693726 5.90693726 5.90693726]\n",
      " [5.72517318 5.72517318 5.72517318 5.72517318]\n",
      " [5.91077934 5.91077934 5.91077934 5.91077934]\n",
      " [5.85272856 5.85272856 5.85272856 5.85272856]\n",
      " [5.71312082 5.71312082 5.71312082 5.71312082]\n",
      " [5.84644354 5.84644354 5.84644354 5.84644354]\n",
      " [5.8429329  5.8429329  5.8429329  5.8429329 ]\n",
      " [5.90675871 5.90675871 5.90675871 5.90675871]\n",
      " [5.90309448 5.90309448 5.90309448 5.90309448]\n",
      " [5.91052446 5.91052446 5.91052446 5.91052446]\n",
      " [5.86806776 5.86806776 5.86806776 5.86806776]\n",
      " [5.84373225 5.84373225 5.84373225 5.84373225]\n",
      " [5.7306232  5.7306232  5.7306232  5.7306232 ]\n",
      " [5.91097774 5.91097774 5.91097774 5.91097774]\n",
      " [5.92704185 5.92704185 5.92704185 5.92704185]\n",
      " [5.92796011 5.92796011 5.92796011 5.92796011]\n",
      " [5.8480578  5.8480578  5.8480578  5.8480578 ]\n",
      " [5.87785461 5.87785461 5.87785461 5.87785461]]\n",
      "Layer Outputs\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[[23.53568213 23.53568213]\n",
      " [21.89871728 21.89871728]\n",
      " [23.54767292 23.54767292]\n",
      " [22.82311525 22.82311525]\n",
      " [23.5629884  23.5629884 ]\n",
      " [23.3315833  23.3315833 ]\n",
      " [22.77507151 22.77507151]\n",
      " [23.30652962 23.30652962]\n",
      " [23.2925353  23.2925353 ]\n",
      " [23.54696116 23.54696116]\n",
      " [23.5323546  23.5323546 ]\n",
      " [23.56197238 23.56197238]\n",
      " [23.39272922 23.39272922]\n",
      " [23.29572174 23.29572174]\n",
      " [22.84484041 22.84484041]\n",
      " [23.56377927 23.56377927]\n",
      " [23.6278149  23.6278149 ]\n",
      " [23.63147531 23.63147531]\n",
      " [23.31296448 23.31296448]\n",
      " [23.43174211 23.43174211]]\n",
      "Delta Last\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.00847249 -0.00847249 -0.00847249 -0.00847249 -0.00847249 -0.00847249]\n",
      " [-0.07079533 -0.07079533 -0.07079533 -0.07079533 -0.07079533 -0.07079533]\n",
      " [-0.00798125 -0.00798125 -0.00798125 -0.00798125 -0.00798125 -0.00798125]\n",
      " [-0.03675801 -0.03675801 -0.03675801 -0.03675801 -0.03675801 -0.03675801]\n",
      " [-0.00735308 -0.00735308 -0.00735308 -0.00735308 -0.00735308 -0.00735308]\n",
      " [-0.01675645 -0.01675645 -0.01675645 -0.01675645 -0.01675645 -0.01675645]\n",
      " [-0.03860096 -0.03860096 -0.03860096 -0.03860096 -0.03860096 -0.03860096]\n",
      " [-0.01776325 -0.01776325 -0.01776325 -0.01776325 -0.01776325 -0.01776325]\n",
      " [-0.01832467 -0.01832467 -0.01832467 -0.01832467 -0.01832467 -0.01832467]\n",
      " [-0.00801043 -0.00801043 -0.00801043 -0.00801043 -0.00801043 -0.00801043]\n",
      " [-0.00860872 -0.00860872 -0.00860872 -0.00860872 -0.00860872 -0.00860872]\n",
      " [-0.00739478 -0.00739478 -0.00739478 -0.00739478 -0.00739478 -0.00739478]\n",
      " [-0.01429001 -0.01429001 -0.01429001 -0.01429001 -0.01429001 -0.01429001]\n",
      " [-0.0181969  -0.0181969  -0.0181969  -0.0181969  -0.0181969  -0.0181969 ]\n",
      " [-0.03592198 -0.03592198 -0.03592198 -0.03592198 -0.03592198 -0.03592198]\n",
      " [-0.00732062 -0.00732062 -0.00732062 -0.00732062 -0.00732062 -0.00732062]\n",
      " [-0.00468508 -0.00468508 -0.00468508 -0.00468508 -0.00468508 -0.00468508]\n",
      " [-0.00453399 -0.00453399 -0.00453399 -0.00453399 -0.00453399 -0.00453399]\n",
      " [-0.01750488 -0.01750488 -0.01750488 -0.01750488 -0.01750488 -0.01750488]\n",
      " [-0.01270949 -0.01270949 -0.01270949 -0.01270949 -0.01270949 -0.01270949]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]\n",
      " [-0.24914083 -0.24914083 -0.24914083 -0.24914083]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Learned\n",
      "0\n",
      "[0.00018023 0.00018023 0.00018023 0.00018023 0.00018023 0.00018023]\n",
      "0\n",
      "Weights\n",
      "[[0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]\n",
      " [0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]\n",
      " [0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]\n",
      " [0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]\n",
      " [0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]\n",
      " [0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]]\n",
      "Learned\n",
      "1\n",
      "[0.0024832 0.0024832 0.0024832 0.0024832]\n",
      "1\n",
      "Weights\n",
      "[[0.9924361 0.9924361 0.9924361 0.9924361 0.9924361 0.9924361]\n",
      " [0.9924361 0.9924361 0.9924361 0.9924361 0.9924361 0.9924361]\n",
      " [0.9924361 0.9924361 0.9924361 0.9924361 0.9924361 0.9924361]\n",
      " [0.9924361 0.9924361 0.9924361 0.9924361 0.9924361 0.9924361]]\n",
      "Learned\n",
      "2\n",
      "[0.00125 0.00125]\n",
      "2\n",
      "Weights\n",
      "[[0.99729363 0.99729363 0.99729363 0.99729363]\n",
      " [0.99729363 0.99729363 0.99729363 0.99729363]]\n",
      "Epoches changed from initial?\n",
      "[[0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]\n",
      " [0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]\n",
      " [0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]\n",
      " [0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]\n",
      " [0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]\n",
      " [0.9900843  0.99009378 0.99007195 0.99005979 0.99008413 0.99008195\n",
      "  0.99008014 0.99010499]]\n",
      "[0.00018023 0.00018023 0.00018023 0.00018023 0.00018023 0.00018023]\n",
      "Epoches changed from initial?\n",
      "[[0.9924361 0.9924361 0.9924361 0.9924361 0.9924361 0.9924361]\n",
      " [0.9924361 0.9924361 0.9924361 0.9924361 0.9924361 0.9924361]\n",
      " [0.9924361 0.9924361 0.9924361 0.9924361 0.9924361 0.9924361]\n",
      " [0.9924361 0.9924361 0.9924361 0.9924361 0.9924361 0.9924361]]\n",
      "[0.0024832 0.0024832 0.0024832 0.0024832]\n",
      "Epoches changed from initial?\n",
      "[[0.99729363 0.99729363 0.99729363 0.99729363]\n",
      " [0.99729363 0.99729363 0.99729363 0.99729363]]\n",
      "[0.00125 0.00125]\n",
      "Layer Outputs\n",
      "[[0.9925078  0.9925078  0.9925078  0.9925078  0.9925078  0.9925078 ]\n",
      " [0.98170128 0.98170128 0.98170128 0.98170128 0.98170128 0.98170128]\n",
      " [0.96133128 0.96133128 0.96133128 0.96133128 0.96133128 0.96133128]\n",
      " [0.98275697 0.98275697 0.98275697 0.98275697 0.98275697 0.98275697]\n",
      " [0.9913572  0.9913572  0.9913572  0.9913572  0.9913572  0.9913572 ]\n",
      " [0.98124589 0.98124589 0.98124589 0.98124589 0.98124589 0.98124589]\n",
      " [0.99186242 0.99186242 0.99186242 0.99186242 0.99186242 0.99186242]\n",
      " [0.99183245 0.99183245 0.99183245 0.99183245 0.99183245 0.99183245]\n",
      " [0.9952394  0.9952394  0.9952394  0.9952394  0.9952394  0.9952394 ]\n",
      " [0.96224672 0.96224672 0.96224672 0.96224672 0.96224672 0.96224672]\n",
      " [0.98111161 0.98111161 0.98111161 0.98111161 0.98111161 0.98111161]\n",
      " [0.98697743 0.98697743 0.98697743 0.98697743 0.98697743 0.98697743]\n",
      " [0.99539364 0.99539364 0.99539364 0.99539364 0.99539364 0.99539364]\n",
      " [0.99121697 0.99121697 0.99121697 0.99121697 0.99121697 0.99121697]\n",
      " [0.99254113 0.99254113 0.99254113 0.99254113 0.99254113 0.99254113]\n",
      " [0.95930679 0.95930679 0.95930679 0.95930679 0.95930679 0.95930679]\n",
      " [0.98533352 0.98533352 0.98533352 0.98533352 0.98533352 0.98533352]\n",
      " [0.92237873 0.92237873 0.92237873 0.92237873 0.92237873 0.92237873]\n",
      " [0.99246497 0.99246497 0.99246497 0.99246497 0.99246497 0.99246497]\n",
      " [0.98197243 0.98197243 0.98197243 0.98197243 0.98197243 0.98197243]]\n",
      "[[4.88637204 4.88637204 4.88637204 4.88637204 4.88637204 4.88637204]\n",
      " [3.98245586 3.98245586 3.98245586 3.98245586 3.98245586 3.98245586]\n",
      " [3.21328808 3.21328808 3.21328808 3.21328808 3.21328808 3.21328808]\n",
      " [4.04295356 4.04295356 4.04295356 4.04295356 4.04295356 4.04295356]\n",
      " [4.74234851 4.74234851 4.74234851 4.74234851 4.74234851 4.74234851]\n",
      " [3.95741012 3.95741012 3.95741012 3.95741012 3.95741012 3.95741012]\n",
      " [4.80309173 4.80309173 4.80309173 4.80309173 4.80309173 4.80309173]\n",
      " [4.79938527 4.79938527 4.79938527 4.79938527 4.79938527 4.79938527]\n",
      " [5.34260915 5.34260915 5.34260915 5.34260915 5.34260915 5.34260915]\n",
      " [3.2381984  3.2381984  3.2381984  3.2381984  3.2381984  3.2381984 ]\n",
      " [3.95013887 3.95013887 3.95013887 3.95013887 3.95013887 3.95013887]\n",
      " [4.32796301 4.32796301 4.32796301 4.32796301 4.32796301 4.32796301]\n",
      " [5.37570045 5.37570045 5.37570045 5.37570045 5.37570045 5.37570045]\n",
      " [4.72611192 4.72611192 4.72611192 4.72611192 4.72611192 4.72611192]\n",
      " [4.89086391 4.89086391 4.89086391 4.89086391 4.89086391 4.89086391]\n",
      " [3.16014956 3.16014956 3.16014956 3.16014956 3.16014956 3.16014956]\n",
      " [4.20741583 4.20741583 4.20741583 4.20741583 4.20741583 4.20741583]\n",
      " [2.47511436 2.47511436 2.47511436 2.47511436 2.47511436 2.47511436]\n",
      " [4.880629   4.880629   4.880629   4.880629   4.880629   4.880629  ]\n",
      " [3.99766071 3.99766071 3.99766071 3.99766071 3.99766071 3.99766071]]\n",
      "Layer Outputs\n",
      "[[5.91248663 5.91248663 5.91248663 5.91248663]\n",
      " [5.84813796 5.84813796 5.84813796 5.84813796]\n",
      " [5.72684243 5.72684243 5.72684243 5.72684243]\n",
      " [5.85442417 5.85442417 5.85442417 5.85442417]\n",
      " [5.90563528 5.90563528 5.90563528 5.90563528]\n",
      " [5.84542629 5.84542629 5.84542629 5.84542629]\n",
      " [5.90864367 5.90864367 5.90864367 5.90864367]\n",
      " [5.9084652  5.9084652  5.9084652  5.9084652 ]\n",
      " [5.92875227 5.92875227 5.92875227 5.92875227]\n",
      " [5.73229349 5.73229349 5.73229349 5.73229349]\n",
      " [5.84462672 5.84462672 5.84462672 5.84462672]\n",
      " [5.8795554  5.8795554  5.8795554  5.8795554 ]\n",
      " [5.92967072 5.92967072 5.92967072 5.92967072]\n",
      " [5.90480025 5.90480025 5.90480025 5.90480025]\n",
      " [5.91268509 5.91268509 5.91268509 5.91268509]\n",
      " [5.71478733 5.71478733 5.71478733 5.71478733]\n",
      " [5.86976659 5.86976659 5.86976659 5.86976659]\n",
      " [5.4948949  5.4948949  5.4948949  5.4948949 ]\n",
      " [5.91223162 5.91223162 5.91223162 5.91223162]\n",
      " [5.84975253 5.84975253 5.84975253 5.84975253]]\n",
      "[[5.91248663 5.91248663 5.91248663 5.91248663]\n",
      " [5.84813796 5.84813796 5.84813796 5.84813796]\n",
      " [5.72684243 5.72684243 5.72684243 5.72684243]\n",
      " [5.85442417 5.85442417 5.85442417 5.85442417]\n",
      " [5.90563528 5.90563528 5.90563528 5.90563528]\n",
      " [5.84542629 5.84542629 5.84542629 5.84542629]\n",
      " [5.90864367 5.90864367 5.90864367 5.90864367]\n",
      " [5.9084652  5.9084652  5.9084652  5.9084652 ]\n",
      " [5.92875227 5.92875227 5.92875227 5.92875227]\n",
      " [5.73229349 5.73229349 5.73229349 5.73229349]\n",
      " [5.84462672 5.84462672 5.84462672 5.84462672]\n",
      " [5.8795554  5.8795554  5.8795554  5.8795554 ]\n",
      " [5.92967072 5.92967072 5.92967072 5.92967072]\n",
      " [5.90480025 5.90480025 5.90480025 5.90480025]\n",
      " [5.91268509 5.91268509 5.91268509 5.91268509]\n",
      " [5.71478733 5.71478733 5.71478733 5.71478733]\n",
      " [5.86976659 5.86976659 5.86976659 5.86976659]\n",
      " [5.4948949  5.4948949  5.4948949  5.4948949 ]\n",
      " [5.91223162 5.91223162 5.91223162 5.91223162]\n",
      " [5.84975253 5.84975253 5.84975253 5.84975253]]\n",
      "Layer Outputs\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "[[23.58719097 23.58719097]\n",
      " [23.33049286 23.33049286]\n",
      " [22.84662383 22.84662383]\n",
      " [23.35556965 23.35556965]\n",
      " [23.55985971 23.55985971]\n",
      " [23.31967555 23.31967555]\n",
      " [23.5718607  23.5718607 ]\n",
      " [23.57114878 23.57114878]\n",
      " [23.65207742 23.65207742]\n",
      " [22.86836908 22.86836908]\n",
      " [23.31648592 23.31648592]\n",
      " [23.45582255 23.45582255]\n",
      " [23.6557413  23.6557413 ]\n",
      " [23.55652863 23.55652863]\n",
      " [23.58798264 23.58798264]\n",
      " [22.79853396 22.79853396]\n",
      " [23.41677324 23.41677324]\n",
      " [21.92134466 21.92134466]\n",
      " [23.58617366 23.58617366]\n",
      " [23.33693369 23.33693369]]\n",
      "Delta Last\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.00735985 -0.00735985 -0.00735985 -0.00735985 -0.00735985 -0.00735985]\n",
      " [-0.01777975 -0.01777975 -0.01777975 -0.01777975 -0.01777975 -0.01777975]\n",
      " [-0.03679243 -0.03679243 -0.03679243 -0.03679243 -0.03679243 -0.03679243]\n",
      " [-0.01677202 -0.01677202 -0.01677202 -0.01677202 -0.01677202 -0.01677202]\n",
      " [-0.00848028 -0.00848028 -0.00848028 -0.00848028 -0.00848028 -0.00848028]\n",
      " [-0.01821377 -0.01821377 -0.01821377 -0.01821377 -0.01821377 -0.01821377]\n",
      " [-0.00798863 -0.00798863 -0.00798863 -0.00798863 -0.00798863 -0.00798863]\n",
      " [-0.00801781 -0.00801781 -0.00801781 -0.00801781 -0.00801781 -0.00801781]\n",
      " [-0.00468938 -0.00468938 -0.00468938 -0.00468938 -0.00468938 -0.00468938]\n",
      " [-0.03595562 -0.03595562 -0.03595562 -0.03595562 -0.03595562 -0.03595562]\n",
      " [-0.01834167 -0.01834167 -0.01834167 -0.01834167 -0.01834167 -0.01834167]\n",
      " [-0.01272124 -0.01272124 -0.01272124 -0.01272124 -0.01272124 -0.01272124]\n",
      " [-0.00453814 -0.00453814 -0.00453814 -0.00453814 -0.00453814 -0.00453814]\n",
      " [-0.00861666 -0.00861666 -0.00861666 -0.00861666 -0.00861666 -0.00861666]\n",
      " [-0.00732736 -0.00732736 -0.00732736 -0.00732736 -0.00732736 -0.00732736]\n",
      " [-0.03863715 -0.03863715 -0.03863715 -0.03863715 -0.03863715 -0.03863715]\n",
      " [-0.01430325 -0.01430325 -0.01430325 -0.01430325 -0.01430325 -0.01430325]\n",
      " [-0.07086237 -0.07086237 -0.07086237 -0.07086237 -0.07086237 -0.07086237]\n",
      " [-0.0074016  -0.0074016  -0.0074016  -0.0074016  -0.0074016  -0.0074016 ]\n",
      " [-0.01752113 -0.01752113 -0.01752113 -0.01752113 -0.01752113 -0.01752113]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]\n",
      " [-0.24932341 -0.24932341 -0.24932341 -0.24932341]]\n",
      "Deltas\n",
      "0\n",
      "[[-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]\n",
      " [-0.125 -0.125]]\n",
      "Learned\n",
      "0\n",
      "[0.00019835 0.00019835 0.00019835 0.00019835 0.00019835 0.00019835]\n",
      "0\n",
      "Weights\n",
      "[[0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]\n",
      " [0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]\n",
      " [0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]\n",
      " [0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]\n",
      " [0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]\n",
      " [0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]]\n",
      "Learned\n",
      "1\n",
      "[0.00273252 0.00273252 0.00273252 0.00273252]\n",
      "1\n",
      "Weights\n",
      "[[0.9926807 0.9926807 0.9926807 0.9926807 0.9926807 0.9926807]\n",
      " [0.9926807 0.9926807 0.9926807 0.9926807 0.9926807 0.9926807]\n",
      " [0.9926807 0.9926807 0.9926807 0.9926807 0.9926807 0.9926807]\n",
      " [0.9926807 0.9926807 0.9926807 0.9926807 0.9926807 0.9926807]]\n",
      "Learned\n",
      "2\n",
      "[0.001375 0.001375]\n",
      "2\n",
      "Weights\n",
      "[[0.99802415 0.99802415 0.99802415 0.99802415]\n",
      " [0.99802415 0.99802415 0.99802415 0.99802415]]\n",
      "Epoches changed from initial?\n",
      "[[0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]\n",
      " [0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]\n",
      " [0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]\n",
      " [0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]\n",
      " [0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]\n",
      " [0.99009277 0.99010321 0.99007918 0.9900658  0.99009259 0.99009019\n",
      "  0.99008819 0.99011554]]\n",
      "[0.00019835 0.00019835 0.00019835 0.00019835 0.00019835 0.00019835]\n",
      "Epoches changed from initial?\n",
      "[[0.9926807 0.9926807 0.9926807 0.9926807 0.9926807 0.9926807]\n",
      " [0.9926807 0.9926807 0.9926807 0.9926807 0.9926807 0.9926807]\n",
      " [0.9926807 0.9926807 0.9926807 0.9926807 0.9926807 0.9926807]\n",
      " [0.9926807 0.9926807 0.9926807 0.9926807 0.9926807 0.9926807]]\n",
      "[0.00273252 0.00273252 0.00273252 0.00273252]\n",
      "Epoches changed from initial?\n",
      "[[0.99802415 0.99802415 0.99802415 0.99802415]\n",
      " [0.99802415 0.99802415 0.99802415 0.99802415]]\n",
      "[0.001375 0.001375]\n",
      "Predict\n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weights_item,bias_item=mini_batch_gradient_descent(gen_data,y_data,list_architecture,learning_rate = 0.001,num_epoches=11,batch_size=20)\n",
    "\n",
    "y_predict=neural_predict(gen_data,weights_item,bias_item,list_architecture)\n",
    "print(\"Predict\")\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8866544445\n",
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "print(0.89561055*0.99 )\n",
    "print(softmax_my(np.array([23.29357914, 23.29357914] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8965\n"
     ]
    }
   ],
   "source": [
    "X_test,y_test=shuffle(X_test,y_test)\n",
    "inputs=X_test[:100,:]  \n",
    "weights=[]\n",
    "neural_architecture= np.array([[784, 300, 1, 0],[300, 100, 1, 0],[100, 10, 3, 0]])\n",
    "activation_functions=neural_architecture[:,2]\n",
    "biases=[]\n",
    "#A list of outputs of each layer\n",
    "h =[]\n",
    "#A list of weightned sum for each layer\n",
    "z=[]\n",
    "deltas= np.zeros(len(neural_architecture), dtype=object)    \n",
    "for layer in range(0, len(neural_architecture)):\n",
    "    #For first time forward propagation random initialization\n",
    "    #weights.append(he_initialization(neural_architecture[layer,1],neural_architecture[layer,0]))\n",
    "    #weights.append(np.zeros(neural_architecture[layer][1],neural_architecture[layer][0]))\n",
    "    #weights.append(np.full((neural_architecture[layer][1], neural_architecture[layer][0]), 0))\n",
    "    weights.append(he_initialization(neural_architecture[layer,1],neural_architecture[layer,0]))\n",
    "    biases.append(np.zeros(neural_architecture[layer][1]))\n",
    "    #Just to store as list\n",
    "print(calculate_prediction(X_test, y_test, weights, biases, activation_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
